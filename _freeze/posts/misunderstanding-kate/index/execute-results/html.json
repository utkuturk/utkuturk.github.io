{
  "hash": "6385938b242bdd977220da8821e75a20",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"misunderstanding Kate's talk on nonuniformity of phonology and phonetics\"\nauthor: Utku Turk\ndate: \"2025-10-29\"\ncategories: [linguistics, misunderstanding, sound, turkish]\ndescription: \"Kate’s asymmetry meets Turkish rounding: evidence that’s gradient but syntactically bounded (also a rant about dual-process framings)\"\nexecute:\n  message: false\n  warning: false\nimage: ./fourier_elephant.png\n---\n\n\n> This post is part of a series I’m calling *Misunderstandings*. The idea is simple: I pick up on talks, papers, or arguments that I admire but also don’t quite buy in the way they’re framed. Sometimes I pose counterexamples, sometimes I just get tangled in the details. The label isn’t meant as dismissive—usually the “misunderstanding” is mine—but I find that pushing on these points is a good way to clarify what’s at stake.\n\nKate Mooney’s recent talk at UMass, *Segmental phonology, gestural phonetics: Explaining asymmetries between phonological and phonetic operations*, was about something deceptively simple: are phonological processes uniform?  \n\nThe traditional view has been “yes.” If an alternation applies freely, that’s phonology. If it’s tied to a particular morpheme, that’s phonology too, just gated by a diacritic, indexed constraint, or cyclic ranking. The assumption is that the underlying machinery is the same; what differs is timing and scope.  \n\nKate pushed back. She focused on vowel harmony versus vowel co-articulation. Zsiga had already argued these belong to different representational domains—rules vs gestures—but Kate sharpened the contrast. Vowel harmony: categorical, typologically robust, governed by rules. Vowel coarticulation: gradient, gestural blending, and crucially never morphologically restricted. That asymmetry, she argued, is real. If you try to collapse the two into one “uniform phonology,” you erase those typological gaps.  \n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(tibble)\n\ngrid <- tibble(\n  x = factor(c(\"Categorical\",\"Categorical\",\"Gradient\",\"Gradient\"),\n             levels = c(\"Categorical\",\"Gradient\")),\n  y = factor(c(\"Restricted\",\"Unrestricted\",\"Restricted\",\"Unrestricted\"),\n             levels = c(\"Restricted\",\"Unrestricted\")),\n  box = c(\"Phonology\", \"—\", \"Empty (predicted)\", \"Phonetics\"),\n  note = c(\"e.g., vowel harmony,\\nmorph. alternations\",\n           \"\",\n           \"“No coarticulation\\nrestricted by morphology”\",\n           \"e.g., coarticulation\")\n)\n\n# numeric positions for highlighting the lower-left tile cleanly\ngrid_num <- grid %>%\n  mutate(xn = as.numeric(x), yn = as.numeric(y))\n\ngg <- ggplot(grid, aes(x, y)) +\n  # tiles and borders\n  geom_tile(fill = \"grey95\", color = \"grey40\", linewidth = 0.6) +\n  # red outline around Gradient + Restricted (predicted empty)\n  geom_rect(\n    data = filter(grid_num, x == \"Gradient\", y == \"Restricted\"),\n    aes(xmin = xn - 0.5, xmax = xn + 0.5, ymin = yn - 0.5, ymax = yn + 0.5),\n    inherit.aes = FALSE, fill = NA, color = \"#bb0000\", linewidth = 1\n  ) +\n  # main labels\n  geom_text(aes(label = box), fontface = \"bold\", vjust = -0.2, size = 4) +\n  # notes beneath each label\n  geom_text(aes(label = note), vjust = 1.2, lineheight = 1.0, size = 3.2) +\n  # put Restricted on top row for readability\n  scale_y_discrete(limits = rev(levels(grid$y))) +\n  labs(x = NULL, y = NULL) +\n  coord_fixed() +\n  theme_minimal(base_size = 12) +\n  theme(\n    panel.grid = element_blank(),\n    axis.text = element_text(face = \"bold\")\n  )\n\ngg\n```\n\n::: {.cell-output-display}\n![A schematic 2×2 for Kate’s asymmetry. The gradient+restricted quadrant is predicted empty.](index_files/figure-html/fig-typology-grid-1.png){#fig-typology-grid width=672}\n:::\n:::\n\n\nIt’s a nice move because it comes with clear predictions. You shouldn’t get consonant copy or epenthesis as general phonotactic repairs, only as morphologically restricted alternations. You shouldn’t get morphologically restricted coarticulation. The grid is crisp: categorical + restricted = phonology, gradient + free = phonetics.  \n\nI should also say I’m not hostile to this move. In fact, I like the idea that phonology and phonetics are not a uniform system. Substance-free phonology has long made a similar claim: phonology is its own representational domain, not reducible to phonetic substance. I’ve always found that perspective appealing, and Kate’s framework fits that general spirit even though she keeps an arm’s-length stance toward committing to any particular theory.\n\nBut I’m suspicious of two-level partitions in general. I feel like in cognitive sciences, whenever there is a hard to explain data, first instinct of many people is to propose a two-level model. Automatic vs controlled processing, System 1 vs System 2 reasoning, parsing vs grammar. Sometimes, this two-level model is needed, especially when it is used to isolate a problem. For example, in the case of I-language idea, it was a powerful tool to carve a theoretical space just to discuss grammar. However, as theorization accumulated, this distinction sometimes used as a pile of \"I-actually-dont-have-any-idea-so-it-might-be-processing\". \n\nThis pattern is everywhere in cognitive science, and all of these frameworks—including what Kate’s suggesting—share the same basic architecture: one process is fast, automatic, and associative; the other is slow, deliberate, and rule-based. The hope is that human behavior can be explained by sorting phenomena into the right bin. And of course, if you set out to show that sometimes people behave automatically and make mistakes;  sometimes they behave deliberately and do not make mistakes, you’ll find confirmation all over the place.\n\nBut as Gawronski, Sherman & Trope (2014) point out, dual-process theories only make progress if they meet a demanding set of conditions: they must specify what the two systems actually are (their operating principles), not just when they operate; they must define the boundaries of each system clearly; and they must generate empirical predictions that could, in principle, be falsified. Otherwise, they collapse into post-hoc labeling—System 1 when it’s effortless, System 2 when it’s not. While dual-process frameworks can be falsifiable in principle, they are often *practically unfalsifiable* because the internal 'systems' aren’t anchored to observable input–output relations. Almost any finding can be retrofitted: if an effect looks automatic, it’s assigned to System 1; if it’s resource-dependent, to System 2.\n\nThat’s my main worry here. Dual-process models are a tempting last resort. They look tidy, but they often function as theories that can’t really lose—precisely the kind that Popper warned us about. John von Neumann put it bluntly: *“With four parameters I can fit an elephant, and with five I can make him wiggle his trunk.”* And if you add one more, you can even make him wink. There’s even an R implementation—the [winking pink elephant](https://www.r-bloggers.com/2011/06/a-winking-pink-elephant/)—that literally draws and animates an elephant with just a handful of parameters. It’s cute, but it’s also the point: if your model is that flexible, fitting isn’t the same thing as explaining. (The original code is base R/MASS heavy, but you can rewrite it cleanly with `ggplot2` and `dplyr`.)  \n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(ggplot2)\n\n# --- parameters (as in your code) ---\nparam  <- c(50-30i, 18+8i, 12-10i, -14-60i, 1+20i)\nparar  <- param * exp(1i*pi/2)                # rotate 90°\ntv     <- seq(0, 2*pi, length.out = 1000)\n\n# Vectorized Fourier helper (same math as your recursive version)\nfourier_vec <- function(tt, cc) {\n  n <- seq_along(cc)\n  cosmat <- cos(outer(tt, n, `*`))\n  sinmat <- sin(outer(tt, n, `*`))\n  as.vector(cosmat %*% Re(cc) + sinmat %*% Im(cc))\n}\n\n# Build one frame\nbuild_curve <- function(i) {\n  Cx <- complex(length(param))\n  Cy <- complex(length(param))\n  Cx[1] <- parar[1] + Im(param[1])\n  Cx[2] <- parar[2] + Im(param[2])\n  Cx[3] <- Re(param[3])\n  Cx[4] <- Re(param[5]) - (i-1)   # trunk wiggle\n  Cx[5] <- Re(param[4])\n\n  Cy[1] <- param[1] - Re(param[1]) + Im(param[4])\n  Cy[2] <- param[2] - Re(param[2])\n  Cy[3] <- param[3] - Re(param[3])\n  # Cy[4:5] remain 0+0i (as in your code)\n\n  x <- fourier_vec(tv, Cx)\n  y <- fourier_vec(tv, Cy)\n\n  # Base plot used: plot(y, -x, ...)\n  data.frame(\n    X = y,\n    Y = -x,\n    frame = factor(i, levels = 1:2, labels = c(\"4 params\",\"5 params\"))\n  )\n}\n\ncurves <- rbind(build_curve(1), build_curve(2))\n\n# Eye: pch=20 (filled) on frame 1, pch=126 (\"~\") on frame 2\neyes <- data.frame(\n  X = rep(Im(param[5]), 2),\n  Y = rep(Im(param[5]), 2),\n  frame = factor(c(\"4 params\",\"5 params\"), levels = c(\"4 params\",\"5 params\")),\n  shape = c(20, 126)\n)\n\np <- ggplot(curves, aes(X, Y)) +\n  # thick red under-stroke\n  geom_path(aes(group = frame), size = 2.5, color = \"red\") +\n  # thinner pink over-stroke\n  geom_path(aes(group = frame), size = 1, color = \"pink\") +\n  # eye (exact pch replication)\n  geom_point(data = eyes, aes(shape = shape), size = 3, color = \"black\") +\n  scale_shape_identity() +\n  coord_fixed() +\n  facet_wrap(~ frame, nrow = 1) +\n  labs(x = \"x\", y = \"y\", title = \"Neumann's Elephant (ggplot)\") +\n  theme_minimal(base_size = 13)\n\n\np_crop <- p\np_crop$layers <- Filter(function(l) !inherits(l$geom, \"GeomPoint\"), p$layers)\np_crop <- p_crop %+% subset(curves, frame == \"4 params\") + coord_fixed() \n\nggsave(\"fourier_elephant.png\", plot = p_crop, width = 8, height = 4, dpi = 300)\n\np \n```\n\n::: {.cell-output-display}\n![“With four parameters I can fit an elephant.” The outline is generated by a short Fourier series using complex coefficients.](index_files/figure-html/fig-elephant-1.png){#fig-elephant fig-align='center' fig-alt='Red–pink outline of an elephant drawn by a Fourier series, shown with axes.' width=80%}\n:::\n:::\n\n\nThat’s where Turkish comes in.  \n\n## The Turkish case  \n\nAs it is almost a common knowledge, Turkish exhibit multiple vowel harmonies. Harmonization spread from left to right. The easier one is the backness/frontness harmony. For example, the plural morpheme in Turkish can surface as either -lar or -ler, depending on the last vowel in the word that they are attaching. It is argued that plural morpheme is underspecified in its backness characteristics. And, whatever the value of the previous vowel, it spread into the plural morpheme.\n\n- [yzym] + /-lAr/ -> [yzymler] \n- [adam] + /-lAr/ -> [adamlar] \n\nAnother present harmony is Backness and Roundness Harmony. For example, the accusative case can surface as -ɨ, -i, -u, -y in Turkish. Again, the way that it is going to surface is completely dependent on the previous vowel. In this case, the accusative case is underspecified for its roundness and backness, but not underspecified for its height, -I. \n\n- [adam] + /-I/ -> [adamɨ]\n- [herif] + /-I/ -> [herifi]\n- [odun] + /-I/ -> [odunu] \n- [yzym] + /-I/ -> [yzymy] \n\nTurkish does not have any other widely accepted vowel harmony apart from these two. This means that Turkish normally doesn’t have free-standing rounding harmony. Moreover, Turkish vowel harmony is strictly word-internal and left-to-right. Backwards harmony is virtually absent. Between-word harmony is nonexistent. \n\nHowever, there is an interesting case in which all of these properties are overhauled. Turkish exhibit optional vowel characteristic change in a very specific environment. In fast production of complex noun phrases (an NP and a modifier), speakers often round the initial vowel of the second NP (NP2) if:  \n\n- The last vowel of NP1 is [+round].  \n- The first vowel of NP2 is [+high, –round].  \n- The second vowel of NP2 is [+round].  \n- NP1 ends in a single consonant (clusters tend to block it).  \n\n<!-- Insert Praat spectrogram/formant track: sequence V[round] – V[high, –round] – V[round], showing F2 lowering in the middle vowel with/without assimilation. -->\n\nExamples (NP1 modifiers in italics):  \n\n- *bir* ikon (one icon) → [bir ikon]  but *on* ikon (ten icons) → [on ykon]\n- *iki* milyon (two millions) → [iki miljon] but *dokuz* milyon (nine millions) → [dokuz mylyon]  \n- *güzel* vizyon (beautiful vision) → [gyzel vizyon] but *hoş* vizyon (nice vision) → [hoʃ vyzyon]\n- *bazı* sigorta (some insurance) → [bazɨ sigorta] but *tüm* sigorta (whole insurance) → [tym sygorta]\n- *tek* biyoloji (single biology) → [tek bijoloʒi] but *vücut* biyoloji (body biology) → [vyʒut byjoloʒi]\n\nNot everything goes through:  \n\n- üç *nilüfer* (three lilies) → [ytʃ nilüfer] (no rounding)  \n- tüm *limon* (whole lemon) → [tym limon] (no rounding)  \n- küçük *işgücü* (small workforce) → [küçük işgücü] (blocked by CC cluster)  \n\n<!-- Insert table: columns for NP1 type, NP1 final vowel, NP2 initial vowel, NP2 second vowel, outcome (rounding / no rounding). Positive vs negative examples grouped. -->\n\nLoanwords are especially revealing. Epenthetic vowels often participate: *hipodrom*, *sigorta*, *diskotek*. Compounds resist, especially when the boundary is vowel–vowel. Some high-frequency words seem entrenched with disharmony, like *dinazor* (originally *dinozor*). There are also asymmetries with labials: sometimes a labial consonant plus a preceding rounded vowel creates the right environment, but not always (*nilüfer* resists).  \n\n<!-- Insert scatterplot or bar chart: proportion of rounding observed by word type—loanwords, compounds, simple NPs, etc. -->\n\n## Why it bugs me  \n\nAt first glance, this seems like a good evidence for Kate's argument. \n\n- It’s optional: It does not necessarily go through, actually you will hear people do not make the rounding bunch of the times. \n- It’s gradient: I do not feel like the vowel quality of the rounded one is similar to other round vowels. \n- It seems to apply semi-automatically in fast speech. \n\nHowever, Kate's argument relies on the non-collapsibility of the quadrant. An event that looks like this should be co-articulation, and should happen irregardless of morphological or syntactic environment. However, that is not the case for this phenomenon. This specific bidirectional vowel harmony, or stuck vowel, only occurs within the syntactically complex DPs. It does not occur within the same word when the same configuration exist. On the contrary, within the same root, there is an additional push for creating disharmony [see [Clements and Sezer](https://brucehayes.org/251VowelHarmony/Readings/ClementsSezer1982TurkishVowelHarmony.pdf)]. \n\nIn phrases that is not dominated by the same syntactic node, this rounding harmony does not occur. For example, in a sentence like (1), one would expect \"ikon\" to be pronounced as [ykon] due to the presence of the adverb dün [dyn] prior to it, however, that is not the case. The same resistance is preserved even if we do not have this string in a place close to the topic area, the left-most phrases in Turkish sentences. The same resistance is still preserved if we place these two elements post-verbally, where they are produced in the same breadth, without a possible prosodic break. \n\n1. Dün ikon aldım \\n `I bought an icon yesterday'\n2. Ben Ahmetlerin dükkanından dün ikon aldım. \\n `I bought an icon yesterday from Ahmets' store'\n3. Ben Ahmetlerin dükkanından aldım dün ikon. \\n `I bought an icon yesterday from Ahmets' store'\n\nThis is exactly the quadrant that Kate’s asymmetry says should be empty: co-articulation is supposed to be gradient and unrestricted, phonology is supposed to be categorical and morphological. Turkish gives you a phenomenon that’s both gradient but restricted.  \n\nMy worry is that the two-level carve—categorical vs gradient, phonology vs phonetics—is just too strong. If phonology is supposed to be categorical and morphologically restricted, and phonetics gradient and unrestricted, what do we do with Turkish? Calling it “just coarticulation” ignores the morphological conditioning. Calling it “phonology” ignores the gradient, variable character.  \n\nMaybe I’m misunderstanding Kate’s point—her claim is typological, and she might be perfectly happy calling Turkish an outlier. But it makes me uneasy. Two-level models are good at drawing clean lines, and that’s why they’re attractive. But reality doesn’t always honor the bins we set up for it. One possibility is that coarticulation might be systematically governed prosodical structure. As of now, I categorize this in terms of nouns and their modifiers. It is possible that this is generalized to other heads and their modifiers. Then the question would be the following: is this rounding-harmony conditioned by prosodical structure that is a by-product of \"head-modifier\" relation or is it conditioned by syntactic locality?\n\n<!-- Insert closing side-by-side Praat spectrograms: one “positive” case (e.g. *ikon* → [ykon]) and one “negative” case (e.g. *nilüfer*), to visually show the subtle but systematic difference. -->\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}
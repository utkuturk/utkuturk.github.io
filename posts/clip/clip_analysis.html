<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.25">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>CLIP Analysis: Validating Unaccusative vs Unergative Scenes – utku turk</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js" integrity="sha384-ZvpUoO/+PpLXR1lu4jmpXWu80pZlYUAfxl5NsBMWOEPSjUn/6Z/hRTt8+pR6L4N2" crossorigin="anonymous"></script><script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-340213ba733b8d01a7d4766ef356faf7.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-4e044b3fe5165e83e0ad5a6dceb68c15.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/quarto-contrib/academicons-1.9.4/all.css" rel="stylesheet">
<link href="../../site_libs/quarto-contrib/academicons-1.9.4/size.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdn.jsdelivr.net/npm/requirejs@2.3.6/require.min.js" integrity="sha384-c9c+LnTbwQ3aujuU7ULEPVvgLs+Fn6fJUvIGTsuu1ZcCf11fiEubah0ttpca4ntM sha384-6V1/AdqZRWk1KAlWbKBlGhN7VG4iE/yAZcO6NZPMF8od0vukrvr0tg4qY6NSrItx" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>
<script src="https://cdn.jsdelivr.net/npm/@jupyter-widgets/html-manager@*/dist/embed-amd.js" crossorigin="anonymous"></script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../styles-v1.css">
</head>

<body class="nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../../index.html" class="navbar-brand navbar-brand-logo">
    </a>
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">utku turk</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../research.html"> 
<span class="menu-text">research</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../papers.html"> 
<span class="menu-text">papers</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../talks.html"> 
<span class="menu-text">talks</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../teaching.html"> 
<span class="menu-text">teaching</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../files/cv.pdf" target="_blank"> 
<span class="menu-text"><i class="ai  ai-cv" aria-label="cv"></i></span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://scholar.google.com/citations?hl=tr&amp;user=wa7LG9gAAAAJ" target="_blank"> 
<span class="menu-text"><i class="ai  ai-google-scholar" aria-label="google-scholar"></i></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/utkuturk" target="_blank"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/UtkuTurkLing" target="_blank"> <i class="bi bi-twitter" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://bsky.app/profile/utkuturk.com" target="_blank"> <i class="bi bi-bluesky" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar"><div class="quarto-margin-header"><div class="margin-header-item">
<div class="margin-spacer" aria-hidden="true" style="height:1px;">

</div>
</div></div>
        
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">CLIP Analysis: Validating Unaccusative vs Unergative Scenes</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>This notebook tests whether unaccusative scenes are perceptually harder to interpret than unergative scenes using CLIP and moondream2 vision-language models.</p>
<section id="setup-and-package-installation" class="level2">
<h2 class="anchored" data-anchor-id="setup-and-package-installation">1. Setup and Package Installation</h2>
<p>First, install required packages (uncomment if running on Colab or similar):</p>
<div id="cell-3" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="09073367-9cbf-4023-c7e6-3ba1bddc1eb0">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install pyvips</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>sudo apt<span class="op">-</span>get update</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>sudo apt<span class="op">-</span>get install <span class="op">-</span>y libvips<span class="op">-</span>dev</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Requirement already satisfied: pyvips in /usr/local/lib/python3.12/dist-packages (3.1.1)
Requirement already satisfied: cffi&gt;=1.0.0 in /usr/local/lib/python3.12/dist-packages (from pyvips) (2.0.0)
Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi&gt;=1.0.0-&gt;pyvips) (2.23)
Hit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease
Hit:2 https://cli.github.com/packages stable InRelease
Hit:3 https://r2u.stat.illinois.edu/ubuntu jammy InRelease
Hit:4 http://security.ubuntu.com/ubuntu jammy-security InRelease
Hit:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease
Hit:6 http://archive.ubuntu.com/ubuntu jammy InRelease
Hit:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease
Hit:8 http://archive.ubuntu.com/ubuntu jammy-backports InRelease
Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease
Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease
Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease
Reading package lists... Done
W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)
Reading package lists... Done
Building dependency tree... Done
Reading state information... Done
libvips-dev is already the newest version (8.12.1-1build1).
0 upgraded, 0 newly installed, 0 to remove and 89 not upgraded.</code></pre>
</div>
</div>
<div id="cell-4" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="7586f5e2-6698-4821-9186-50e842586820">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Uncomment these lines if running on Google Colab or a fresh environment</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install torch torchvision</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install git<span class="op">+</span>https:<span class="op">//</span>github.com<span class="op">/</span>openai<span class="op">/</span>CLIP.git</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install transformers</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install pillow pandas numpy matplotlib seaborn scikit<span class="op">-</span>learn scipy</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)
Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.24.0+cu126)
Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.2)
Requirement already satisfied: typing-extensions&gt;=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)
Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)
Requirement already satisfied: sympy&gt;=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)
Requirement already satisfied: networkx&gt;=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)
Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)
Requirement already satisfied: fsspec&gt;=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)
Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)
Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)
Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)
Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)
Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)
Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)
Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)
Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)
Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)
Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)
Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)
Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)
Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)
Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)
Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)
Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)
Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)
Requirement already satisfied: pillow!=8.3.*,&gt;=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)
Requirement already satisfied: mpmath&lt;1.4,&gt;=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy&gt;=1.13.3-&gt;torch) (1.3.0)
Requirement already satisfied: MarkupSafe&gt;=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2-&gt;torch) (3.0.3)
Collecting git+https://github.com/openai/CLIP.git
  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-ojtv866k
  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-ojtv866k
  Resolved https://github.com/openai/CLIP.git to commit dcba3cb2e2827b402d2701e7e1c7d9fed8a20ef1
  Preparing metadata (setup.py) ... done
Requirement already satisfied: ftfy in /usr/local/lib/python3.12/dist-packages (from clip==1.0) (6.3.1)
Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from clip==1.0) (25.0)
Requirement already satisfied: regex in /usr/local/lib/python3.12/dist-packages (from clip==1.0) (2025.11.3)
Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from clip==1.0) (4.67.1)
Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from clip==1.0) (2.9.0+cu126)
Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from clip==1.0) (0.24.0+cu126)
Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from ftfy-&gt;clip==1.0) (0.2.14)
Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch-&gt;clip==1.0) (3.20.2)
Requirement already satisfied: typing-extensions&gt;=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch-&gt;clip==1.0) (4.15.0)
Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch-&gt;clip==1.0) (75.2.0)
Requirement already satisfied: sympy&gt;=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch-&gt;clip==1.0) (1.14.0)
Requirement already satisfied: networkx&gt;=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch-&gt;clip==1.0) (3.6.1)
Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch-&gt;clip==1.0) (3.1.6)
Requirement already satisfied: fsspec&gt;=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch-&gt;clip==1.0) (2025.3.0)
Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch-&gt;clip==1.0) (12.6.77)
Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch-&gt;clip==1.0) (12.6.77)
Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch-&gt;clip==1.0) (12.6.80)
Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch-&gt;clip==1.0) (9.10.2.21)
Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch-&gt;clip==1.0) (12.6.4.1)
Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch-&gt;clip==1.0) (11.3.0.4)
Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch-&gt;clip==1.0) (10.3.7.77)
Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch-&gt;clip==1.0) (11.7.1.2)
Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch-&gt;clip==1.0) (12.5.4.2)
Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch-&gt;clip==1.0) (0.7.1)
Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch-&gt;clip==1.0) (2.27.5)
Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch-&gt;clip==1.0) (3.3.20)
Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch-&gt;clip==1.0) (12.6.77)
Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch-&gt;clip==1.0) (12.6.85)
Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch-&gt;clip==1.0) (1.11.1.6)
Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch-&gt;clip==1.0) (3.5.0)
Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision-&gt;clip==1.0) (2.0.2)
Requirement already satisfied: pillow!=8.3.*,&gt;=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision-&gt;clip==1.0) (11.3.0)
Requirement already satisfied: mpmath&lt;1.4,&gt;=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy&gt;=1.13.3-&gt;torch-&gt;clip==1.0) (1.3.0)
Requirement already satisfied: MarkupSafe&gt;=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2-&gt;torch-&gt;clip==1.0) (3.0.3)
Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.37.2)
Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.2)
Requirement already satisfied: huggingface-hub&lt;1.0,&gt;=0.19.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)
Requirement already satisfied: numpy&gt;=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)
Requirement already satisfied: packaging&gt;=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)
Requirement already satisfied: pyyaml&gt;=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)
Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)
Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)
Requirement already satisfied: tokenizers&lt;0.19,&gt;=0.14 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.15.2)
Requirement already satisfied: safetensors&gt;=0.4.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)
Requirement already satisfied: tqdm&gt;=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)
Requirement already satisfied: fsspec&gt;=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub&lt;1.0,&gt;=0.19.3-&gt;transformers) (2025.3.0)
Requirement already satisfied: typing-extensions&gt;=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub&lt;1.0,&gt;=0.19.3-&gt;transformers) (4.15.0)
Requirement already satisfied: hf-xet&lt;2.0.0,&gt;=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub&lt;1.0,&gt;=0.19.3-&gt;transformers) (1.2.0)
Requirement already satisfied: charset_normalizer&lt;4,&gt;=2 in /usr/local/lib/python3.12/dist-packages (from requests-&gt;transformers) (3.4.4)
Requirement already satisfied: idna&lt;4,&gt;=2.5 in /usr/local/lib/python3.12/dist-packages (from requests-&gt;transformers) (3.11)
Requirement already satisfied: urllib3&lt;3,&gt;=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests-&gt;transformers) (2.5.0)
Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests-&gt;transformers) (2026.1.4)
Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)
Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)
Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)
Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)
Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (0.13.2)
Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)
Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (1.16.3)
Requirement already satisfied: python-dateutil&gt;=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)
Requirement already satisfied: pytz&gt;=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)
Requirement already satisfied: tzdata&gt;=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.3)
Requirement already satisfied: contourpy&gt;=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)
Requirement already satisfied: cycler&gt;=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)
Requirement already satisfied: fonttools&gt;=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.61.1)
Requirement already satisfied: kiwisolver&gt;=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)
Requirement already satisfied: packaging&gt;=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)
Requirement already satisfied: pyparsing&gt;=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.3.1)
Requirement already satisfied: joblib&gt;=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.3)
Requirement already satisfied: threadpoolctl&gt;=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)
Requirement already satisfied: six&gt;=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil&gt;=2.8.2-&gt;pandas) (1.17.0)</code></pre>
</div>
</div>
<div id="cell-5" class="cell" data-execution_count="26">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="co"># ============================================================================</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Configuration</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="co"># ============================================================================</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> re</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Disable MPS fallback to avoid device mismatch issues with VLMs</span></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>os.environ[<span class="st">'PYTORCH_ENABLE_MPS_FALLBACK'</span>] <span class="op">=</span> <span class="st">'1'</span></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>os.environ[<span class="st">'PYTORCH_CUDA_ALLOC_CONF'</span>] <span class="op">=</span> <span class="st">'expandable_segments:True'</span></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> clip</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> PIL <span class="im">import</span> Image</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> AutoModelForCausalLM, AutoTokenizer</span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> MinMaxScaler</span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> pearsonr</span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Set up plotting style</span></span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a>sns.set_style(<span class="st">"whitegrid"</span>)</span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a>plt.rcParams[<span class="st">'figure.figsize'</span>] <span class="op">=</span> (<span class="dv">10</span>, <span class="dv">6</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="cell-6" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:190,&quot;referenced_widgets&quot;:[&quot;d5677f4560054247957effc97c0381c1&quot;,&quot;ebddbcacb7d84c3f935f0bde56e24997&quot;,&quot;71d8a2bb22cd49149c98ca4c6d2886e8&quot;,&quot;79c5502b53ab460dad47c9006f1bc0b7&quot;,&quot;1aa4269a7392475cb9546b1db9afb965&quot;,&quot;b8984b171b3a4d9eb6488032317ce259&quot;,&quot;4553dc8db2b34ccd8e73991afdbea17d&quot;,&quot;c33bd63aaed84df99c64739a78a8a712&quot;,&quot;536cf52b6f744767bd83a93580b71288&quot;,&quot;3367afddaa6e45f0807ff275abb7afc6&quot;,&quot;9573e575864e4c24b3b37be971ac9c8e&quot;]}}" data-outputid="6a26931f-3160-41c7-8dce-f61bed1c214b" data-execution_count="27">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="co"># ============================================================================</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Configuration</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="co"># ============================================================================</span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>CACHE_FILE <span class="op">=</span> <span class="st">"./cached_scores.csv"</span></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>TEST_MODE <span class="op">=</span> <span class="va">False</span>  <span class="co"># Set to True to process only 1 item from each verb type</span></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a><span class="co"># ============================================================================</span></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Load Models</span></span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a><span class="co"># ============================================================================</span></span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Loading models..."</span>)</span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Load CLIP model</span></span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Note: We use CPU for everything if MPS is detected to avoid VLM issues, or if CUDA OOM occurs.</span></span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Explicitly setting device to "cpu" to avoid OutOfMemoryError for CLIP on GPU.</span></span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> <span class="st">"cpu"</span></span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> torch.cuda.is_available():</span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"⚠️  CUDA is available but forcing CPU for CLIP to prevent OOM errors."</span>)</span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a><span class="cf">elif</span> <span class="bu">hasattr</span>(torch.backends, <span class="st">'mps'</span>) <span class="kw">and</span> torch.backends.mps.is_available():</span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"⚠️  MPS detected but using CPU for compatibility with VLMs."</span>)</span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a>model_clip, preprocess <span class="op">=</span> clip.load(<span class="st">"ViT-B/32"</span>, device<span class="op">=</span>device, jit<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"✓ CLIP model loaded on </span><span class="sc">{</span>device<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-27"><a href="#cb6-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Load Qwen-VL-Chat model</span></span>
<span id="cb6-28"><a href="#cb6-28" aria-hidden="true" tabindex="-1"></a>model_id <span class="op">=</span> <span class="st">"Qwen/Qwen-VL-Chat"</span></span>
<span id="cb6-29"><a href="#cb6-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-30"><a href="#cb6-30" aria-hidden="true" tabindex="-1"></a>model_vlm <span class="op">=</span> AutoModelForCausalLM.from_pretrained(</span>
<span id="cb6-31"><a href="#cb6-31" aria-hidden="true" tabindex="-1"></a>    model_id,</span>
<span id="cb6-32"><a href="#cb6-32" aria-hidden="true" tabindex="-1"></a>    trust_remote_code<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb6-33"><a href="#cb6-33" aria-hidden="true" tabindex="-1"></a>    torch_dtype<span class="op">=</span>torch.float32 <span class="co"># Explicitly set to float32</span></span>
<span id="cb6-34"><a href="#cb6-34" aria-hidden="true" tabindex="-1"></a>).to(<span class="st">'cpu'</span>) <span class="co"># Explicitly move to CPU</span></span>
<span id="cb6-35"><a href="#cb6-35" aria-hidden="true" tabindex="-1"></a>tokenizer_vlm <span class="op">=</span> AutoTokenizer.from_pretrained(model_id, trust_remote_code<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb6-36"><a href="#cb6-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-37"><a href="#cb6-37" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"✓ Qwen-VL-Chat model loaded on </span><span class="sc">{</span>model_vlm<span class="sc">.</span>device<span class="sc">}</span><span class="ss">"</span>) <span class="co"># Confirm device</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Loading models...
⚠️  CUDA is available but forcing CPU for CLIP to prevent OOM errors.
✓ CLIP model loaded on cpu</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
WARNING:transformers_modules.Qwen.Qwen-VL-Chat.f57cfbd358cb56b710d963669ad1bcfb44cdcdd8.modeling_qwen:The model is automatically converting to bf16 for faster inference. If you want to disable the automatic precision, please manually add bf16/fp16/fp32=True to "AutoModelForCausalLM.from_pretrained".</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"version_major":2,"version_minor":0,"model_id":"d5677f4560054247957effc97c0381c1","quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>✓ Qwen-VL-Chat model loaded on cpu</code></pre>
</div>
</div>
<div id="cell-7" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="ecabd685-654e-4bd1-84e7-2ba72b43a201" data-execution_count="28">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="co"># ============================================================================</span></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Data Structure</span></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a><span class="co"># ============================================================================</span></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Unergative scenes</span></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>df_unerg <span class="op">=</span> pd.DataFrame({</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Filename"</span>: [</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>        <span class="st">"./octopus_swim.jpg"</span>,</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>        <span class="st">"./ballerina_run.jpg"</span>,</span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>        <span class="st">"./boy_float.jpg"</span>,</span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>        <span class="st">"./chef_yell.jpg"</span>,</span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>        <span class="st">"./clown_walk.jpg"</span>,</span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a>        <span class="st">"./cowboy_wink.jpg"</span>,</span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a>        <span class="st">"./dog_bark.jpg"</span>,</span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a>        <span class="st">"./monkey_sleep.jpg"</span>,</span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a>        <span class="st">"./penguin_sneeze.jpg"</span>,</span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a>        <span class="st">"./pirate_cough.jpg"</span>,</span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a>        <span class="st">"./rabbit_smile.jpg"</span>,</span>
<span id="cb10-20"><a href="#cb10-20" aria-hidden="true" tabindex="-1"></a>        <span class="st">"./snail_crawl.jpg"</span>,</span>
<span id="cb10-21"><a href="#cb10-21" aria-hidden="true" tabindex="-1"></a>    ],</span>
<span id="cb10-22"><a href="#cb10-22" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Sentence"</span>: [</span>
<span id="cb10-23"><a href="#cb10-23" aria-hidden="true" tabindex="-1"></a>        <span class="st">"The octopus is swimming."</span>,</span>
<span id="cb10-24"><a href="#cb10-24" aria-hidden="true" tabindex="-1"></a>        <span class="st">"The ballerina is running."</span>,</span>
<span id="cb10-25"><a href="#cb10-25" aria-hidden="true" tabindex="-1"></a>        <span class="st">"The boy is floating."</span>,</span>
<span id="cb10-26"><a href="#cb10-26" aria-hidden="true" tabindex="-1"></a>        <span class="st">"The chef is yelling."</span>,</span>
<span id="cb10-27"><a href="#cb10-27" aria-hidden="true" tabindex="-1"></a>        <span class="st">"The clown is walking."</span>,</span>
<span id="cb10-28"><a href="#cb10-28" aria-hidden="true" tabindex="-1"></a>        <span class="st">"The cowboy is winking."</span>,</span>
<span id="cb10-29"><a href="#cb10-29" aria-hidden="true" tabindex="-1"></a>        <span class="st">"The dog is barking."</span>,</span>
<span id="cb10-30"><a href="#cb10-30" aria-hidden="true" tabindex="-1"></a>        <span class="st">"The monkey is sleeping."</span>,</span>
<span id="cb10-31"><a href="#cb10-31" aria-hidden="true" tabindex="-1"></a>        <span class="st">"The penguin is sneezing."</span>,</span>
<span id="cb10-32"><a href="#cb10-32" aria-hidden="true" tabindex="-1"></a>        <span class="st">"The pirate is coughing."</span>,</span>
<span id="cb10-33"><a href="#cb10-33" aria-hidden="true" tabindex="-1"></a>        <span class="st">"The rabbit is smiling."</span>,</span>
<span id="cb10-34"><a href="#cb10-34" aria-hidden="true" tabindex="-1"></a>        <span class="st">"The snail is crawling."</span>,</span>
<span id="cb10-35"><a href="#cb10-35" aria-hidden="true" tabindex="-1"></a>    ]</span>
<span id="cb10-36"><a href="#cb10-36" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb10-37"><a href="#cb10-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-38"><a href="#cb10-38" aria-hidden="true" tabindex="-1"></a><span class="co"># Unaccusative scenes</span></span>
<span id="cb10-39"><a href="#cb10-39" aria-hidden="true" tabindex="-1"></a>df_unacc <span class="op">=</span> pd.DataFrame({</span>
<span id="cb10-40"><a href="#cb10-40" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Filename"</span>: [</span>
<span id="cb10-41"><a href="#cb10-41" aria-hidden="true" tabindex="-1"></a>        <span class="st">"./octopus_boil.jpg"</span>,</span>
<span id="cb10-42"><a href="#cb10-42" aria-hidden="true" tabindex="-1"></a>        <span class="st">"./ballerina_shrink.jpg"</span>,</span>
<span id="cb10-43"><a href="#cb10-43" aria-hidden="true" tabindex="-1"></a>        <span class="st">"./boy_yawn.jpg"</span>,</span>
<span id="cb10-44"><a href="#cb10-44" aria-hidden="true" tabindex="-1"></a>        <span class="st">"./chef_drown.jpg"</span>,</span>
<span id="cb10-45"><a href="#cb10-45" aria-hidden="true" tabindex="-1"></a>        <span class="st">"./clown_grow.jpg"</span>,</span>
<span id="cb10-46"><a href="#cb10-46" aria-hidden="true" tabindex="-1"></a>        <span class="st">"./cowboy_fall.jpg"</span>,</span>
<span id="cb10-47"><a href="#cb10-47" aria-hidden="true" tabindex="-1"></a>        <span class="st">"./dog_spin.jpg"</span>,</span>
<span id="cb10-48"><a href="#cb10-48" aria-hidden="true" tabindex="-1"></a>        <span class="st">"./monkey_trip.jpg"</span>,</span>
<span id="cb10-49"><a href="#cb10-49" aria-hidden="true" tabindex="-1"></a>        <span class="st">"./penguin_bounce.jpg"</span>,</span>
<span id="cb10-50"><a href="#cb10-50" aria-hidden="true" tabindex="-1"></a>        <span class="st">"./pirate_sink.jpg"</span>,</span>
<span id="cb10-51"><a href="#cb10-51" aria-hidden="true" tabindex="-1"></a>        <span class="st">"./rabbit_shake.jpg"</span>,</span>
<span id="cb10-52"><a href="#cb10-52" aria-hidden="true" tabindex="-1"></a>        <span class="st">"./snail_melt.jpg"</span>,</span>
<span id="cb10-53"><a href="#cb10-53" aria-hidden="true" tabindex="-1"></a>    ],</span>
<span id="cb10-54"><a href="#cb10-54" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Sentence"</span>: [</span>
<span id="cb10-55"><a href="#cb10-55" aria-hidden="true" tabindex="-1"></a>        <span class="st">"The octopus is boiling."</span>,</span>
<span id="cb10-56"><a href="#cb10-56" aria-hidden="true" tabindex="-1"></a>        <span class="st">"The ballerina is shrinking."</span>,</span>
<span id="cb10-57"><a href="#cb10-57" aria-hidden="true" tabindex="-1"></a>        <span class="st">"The boy is yawning."</span>,</span>
<span id="cb10-58"><a href="#cb10-58" aria-hidden="true" tabindex="-1"></a>        <span class="st">"The chef is drowning."</span>,</span>
<span id="cb10-59"><a href="#cb10-59" aria-hidden="true" tabindex="-1"></a>        <span class="st">"The clown is growing."</span>,</span>
<span id="cb10-60"><a href="#cb10-60" aria-hidden="true" tabindex="-1"></a>        <span class="st">"The cowboy is falling."</span>,</span>
<span id="cb10-61"><a href="#cb10-61" aria-hidden="true" tabindex="-1"></a>        <span class="st">"The dog is spinning."</span>,</span>
<span id="cb10-62"><a href="#cb10-62" aria-hidden="true" tabindex="-1"></a>        <span class="st">"The monkey is tripping."</span>,</span>
<span id="cb10-63"><a href="#cb10-63" aria-hidden="true" tabindex="-1"></a>        <span class="st">"The penguin is bouncing."</span>,</span>
<span id="cb10-64"><a href="#cb10-64" aria-hidden="true" tabindex="-1"></a>        <span class="st">"The pirate is sinking."</span>,</span>
<span id="cb10-65"><a href="#cb10-65" aria-hidden="true" tabindex="-1"></a>        <span class="st">"The rabbit is shaking."</span>,</span>
<span id="cb10-66"><a href="#cb10-66" aria-hidden="true" tabindex="-1"></a>        <span class="st">"The snail is melting."</span>,</span>
<span id="cb10-67"><a href="#cb10-67" aria-hidden="true" tabindex="-1"></a>    ]</span>
<span id="cb10-68"><a href="#cb10-68" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb10-69"><a href="#cb10-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-70"><a href="#cb10-70" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Loaded </span><span class="sc">{</span><span class="bu">len</span>(df_unerg)<span class="sc">}</span><span class="ss"> unergative scenes"</span>)</span>
<span id="cb10-71"><a href="#cb10-71" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Loaded </span><span class="sc">{</span><span class="bu">len</span>(df_unacc)<span class="sc">}</span><span class="ss"> unaccusative scenes"</span>)</span>
<span id="cb10-72"><a href="#cb10-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-73"><a href="#cb10-73" aria-hidden="true" tabindex="-1"></a><span class="co"># ============================================================================</span></span>
<span id="cb10-74"><a href="#cb10-74" aria-hidden="true" tabindex="-1"></a><span class="co"># Analysis Functions</span></span>
<span id="cb10-75"><a href="#cb10-75" aria-hidden="true" tabindex="-1"></a><span class="co"># ============================================================================</span></span>
<span id="cb10-76"><a href="#cb10-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-77"><a href="#cb10-77" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> compute_clip_similarity(df, model, preprocess, device):</span>
<span id="cb10-78"><a href="#cb10-78" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb10-79"><a href="#cb10-79" aria-hidden="true" tabindex="-1"></a><span class="co">    Compute CLIP similarity scores for image-text pairs.</span></span>
<span id="cb10-80"><a href="#cb10-80" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb10-81"><a href="#cb10-81" aria-hidden="true" tabindex="-1"></a>    similarity_scores <span class="op">=</span> []</span>
<span id="cb10-82"><a href="#cb10-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-83"><a href="#cb10-83" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> _, row <span class="kw">in</span> df.iterrows():</span>
<span id="cb10-84"><a href="#cb10-84" aria-hidden="true" tabindex="-1"></a>        img_path <span class="op">=</span> row[<span class="st">'Filename'</span>]</span>
<span id="cb10-85"><a href="#cb10-85" aria-hidden="true" tabindex="-1"></a>        text <span class="op">=</span> row[<span class="st">'Sentence'</span>]</span>
<span id="cb10-86"><a href="#cb10-86" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-87"><a href="#cb10-87" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Preprocess image and tokenize text</span></span>
<span id="cb10-88"><a href="#cb10-88" aria-hidden="true" tabindex="-1"></a>        img <span class="op">=</span> preprocess(Image.<span class="bu">open</span>(img_path)).unsqueeze(<span class="dv">0</span>).to(device)</span>
<span id="cb10-89"><a href="#cb10-89" aria-hidden="true" tabindex="-1"></a>        text_tokenized <span class="op">=</span> clip.tokenize([text]).to(device)</span>
<span id="cb10-90"><a href="#cb10-90" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-91"><a href="#cb10-91" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Compute similarity</span></span>
<span id="cb10-92"><a href="#cb10-92" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> torch.no_grad():</span>
<span id="cb10-93"><a href="#cb10-93" aria-hidden="true" tabindex="-1"></a>            logits_per_image, _ <span class="op">=</span> model(img, text_tokenized)</span>
<span id="cb10-94"><a href="#cb10-94" aria-hidden="true" tabindex="-1"></a>            similarity_score <span class="op">=</span> logits_per_image.item()</span>
<span id="cb10-95"><a href="#cb10-95" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-96"><a href="#cb10-96" aria-hidden="true" tabindex="-1"></a>        similarity_scores.append(similarity_score)</span>
<span id="cb10-97"><a href="#cb10-97" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-98"><a href="#cb10-98" aria-hidden="true" tabindex="-1"></a>    df_copy <span class="op">=</span> df.copy()</span>
<span id="cb10-99"><a href="#cb10-99" aria-hidden="true" tabindex="-1"></a>    df_copy[<span class="st">'CLIP_Similarity'</span>] <span class="op">=</span> similarity_scores</span>
<span id="cb10-100"><a href="#cb10-100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-101"><a href="#cb10-101" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> df_copy</span>
<span id="cb10-102"><a href="#cb10-102" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-103"><a href="#cb10-103" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-104"><a href="#cb10-104" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> compute_subject_salience(df, model, preprocess, device):</span>
<span id="cb10-105"><a href="#cb10-105" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb10-106"><a href="#cb10-106" aria-hidden="true" tabindex="-1"></a><span class="co">    Compute CLIP similarity scores for subject noun alone.</span></span>
<span id="cb10-107"><a href="#cb10-107" aria-hidden="true" tabindex="-1"></a><span class="co">    This measures how visually salient/easy to identify the subject is.</span></span>
<span id="cb10-108"><a href="#cb10-108" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb10-109"><a href="#cb10-109" aria-hidden="true" tabindex="-1"></a>    subject_scores <span class="op">=</span> []</span>
<span id="cb10-110"><a href="#cb10-110" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-111"><a href="#cb10-111" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> _, row <span class="kw">in</span> df.iterrows():</span>
<span id="cb10-112"><a href="#cb10-112" aria-hidden="true" tabindex="-1"></a>        img_path <span class="op">=</span> row[<span class="st">'Filename'</span>]</span>
<span id="cb10-113"><a href="#cb10-113" aria-hidden="true" tabindex="-1"></a>        sentence <span class="op">=</span> row[<span class="st">'Sentence'</span>]</span>
<span id="cb10-114"><a href="#cb10-114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-115"><a href="#cb10-115" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Extract subject noun (assumes format "The X is ...")</span></span>
<span id="cb10-116"><a href="#cb10-116" aria-hidden="true" tabindex="-1"></a>        subject <span class="op">=</span> sentence.split(<span class="st">"The "</span>)[<span class="dv">1</span>].split(<span class="st">" is"</span>)[<span class="dv">0</span>]</span>
<span id="cb10-117"><a href="#cb10-117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-118"><a href="#cb10-118" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Preprocess image and tokenize subject</span></span>
<span id="cb10-119"><a href="#cb10-119" aria-hidden="true" tabindex="-1"></a>        img <span class="op">=</span> preprocess(Image.<span class="bu">open</span>(img_path)).unsqueeze(<span class="dv">0</span>).to(device)</span>
<span id="cb10-120"><a href="#cb10-120" aria-hidden="true" tabindex="-1"></a>        text_tokenized <span class="op">=</span> clip.tokenize([subject]).to(device)</span>
<span id="cb10-121"><a href="#cb10-121" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-122"><a href="#cb10-122" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Compute similarity</span></span>
<span id="cb10-123"><a href="#cb10-123" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> torch.no_grad():</span>
<span id="cb10-124"><a href="#cb10-124" aria-hidden="true" tabindex="-1"></a>            logits_per_image, _ <span class="op">=</span> model(img, text_tokenized)</span>
<span id="cb10-125"><a href="#cb10-125" aria-hidden="true" tabindex="-1"></a>            similarity_score <span class="op">=</span> logits_per_image.item()</span>
<span id="cb10-126"><a href="#cb10-126" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-127"><a href="#cb10-127" aria-hidden="true" tabindex="-1"></a>        subject_scores.append(similarity_score)</span>
<span id="cb10-128"><a href="#cb10-128" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-129"><a href="#cb10-129" aria-hidden="true" tabindex="-1"></a>    df_copy <span class="op">=</span> df.copy()</span>
<span id="cb10-130"><a href="#cb10-130" aria-hidden="true" tabindex="-1"></a>    df_copy[<span class="st">'Subject_Salience'</span>] <span class="op">=</span> subject_scores</span>
<span id="cb10-131"><a href="#cb10-131" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-132"><a href="#cb10-132" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> df_copy</span>
<span id="cb10-133"><a href="#cb10-133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-134"><a href="#cb10-134" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-135"><a href="#cb10-135" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> compute_qwen_scores(df, model, tokenizer):</span>
<span id="cb10-136"><a href="#cb10-136" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb10-137"><a href="#cb10-137" aria-hidden="true" tabindex="-1"></a><span class="co">    Compute verification scores using Qwen-VL-Chat multimodal LLM.</span></span>
<span id="cb10-138"><a href="#cb10-138" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb10-139"><a href="#cb10-139" aria-hidden="true" tabindex="-1"></a>    scores <span class="op">=</span> []</span>
<span id="cb10-140"><a href="#cb10-140" aria-hidden="true" tabindex="-1"></a>    responses <span class="op">=</span> []</span>
<span id="cb10-141"><a href="#cb10-141" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-142"><a href="#cb10-142" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> idx, row <span class="kw">in</span> df.iterrows():</span>
<span id="cb10-143"><a href="#cb10-143" aria-hidden="true" tabindex="-1"></a>        img_path <span class="op">=</span> row[<span class="st">'Filename'</span>]</span>
<span id="cb10-144"><a href="#cb10-144" aria-hidden="true" tabindex="-1"></a>        sentence <span class="op">=</span> row[<span class="st">'Sentence'</span>]</span>
<span id="cb10-145"><a href="#cb10-145" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-146"><a href="#cb10-146" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"  Processing item </span><span class="sc">{</span>idx<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">/</span><span class="sc">{</span><span class="bu">len</span>(df)<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>sentence<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb10-147"><a href="#cb10-147" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-148"><a href="#cb10-148" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Create query for Qwen-VL-Chat</span></span>
<span id="cb10-149"><a href="#cb10-149" aria-hidden="true" tabindex="-1"></a>        query <span class="op">=</span> tokenizer.from_list_format([</span>
<span id="cb10-150"><a href="#cb10-150" aria-hidden="true" tabindex="-1"></a>            {<span class="st">'image'</span>: img_path},</span>
<span id="cb10-151"><a href="#cb10-151" aria-hidden="true" tabindex="-1"></a>            {<span class="st">'text'</span>: <span class="ss">f'Rate how well this sentence describes the image: "</span><span class="sc">{</span>sentence<span class="sc">}</span><span class="ss">"</span><span class="ch">\n</span><span class="ss">Score from 1-10 (1=mismatch, 10=perfect match). Reply with just the number.'</span>},</span>
<span id="cb10-152"><a href="#cb10-152" aria-hidden="true" tabindex="-1"></a>        ])</span>
<span id="cb10-153"><a href="#cb10-153" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-154"><a href="#cb10-154" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Generate response</span></span>
<span id="cb10-155"><a href="#cb10-155" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> torch.no_grad():</span>
<span id="cb10-156"><a href="#cb10-156" aria-hidden="true" tabindex="-1"></a>            response, _ <span class="op">=</span> model.chat(tokenizer, query<span class="op">=</span>query, history<span class="op">=</span><span class="va">None</span>)</span>
<span id="cb10-157"><a href="#cb10-157" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-158"><a href="#cb10-158" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Extract numeric score</span></span>
<span id="cb10-159"><a href="#cb10-159" aria-hidden="true" tabindex="-1"></a>        <span class="cf">try</span>:</span>
<span id="cb10-160"><a href="#cb10-160" aria-hidden="true" tabindex="-1"></a>            match <span class="op">=</span> re.search(<span class="vs">r'</span><span class="kw">(</span><span class="dv">\d</span><span class="op">+</span>(?:<span class="ch">\.</span><span class="dv">\d</span><span class="op">+</span>)<span class="op">?</span><span class="kw">)</span><span class="vs">'</span>, response)</span>
<span id="cb10-161"><a href="#cb10-161" aria-hidden="true" tabindex="-1"></a>            score <span class="op">=</span> <span class="bu">float</span>(match.group(<span class="dv">1</span>)) <span class="cf">if</span> match <span class="cf">else</span> <span class="fl">5.0</span></span>
<span id="cb10-162"><a href="#cb10-162" aria-hidden="true" tabindex="-1"></a>            score <span class="op">=</span> <span class="bu">min</span>(<span class="fl">10.0</span>, <span class="bu">max</span>(<span class="fl">1.0</span>, score))  <span class="co"># Clamp to 1-10</span></span>
<span id="cb10-163"><a href="#cb10-163" aria-hidden="true" tabindex="-1"></a>        <span class="cf">except</span>:</span>
<span id="cb10-164"><a href="#cb10-164" aria-hidden="true" tabindex="-1"></a>            score <span class="op">=</span> <span class="fl">5.0</span></span>
<span id="cb10-165"><a href="#cb10-165" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-166"><a href="#cb10-166" aria-hidden="true" tabindex="-1"></a>        scores.append(score)</span>
<span id="cb10-167"><a href="#cb10-167" aria-hidden="true" tabindex="-1"></a>        responses.append(response)</span>
<span id="cb10-168"><a href="#cb10-168" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-169"><a href="#cb10-169" aria-hidden="true" tabindex="-1"></a>    df_copy <span class="op">=</span> df.copy()</span>
<span id="cb10-170"><a href="#cb10-170" aria-hidden="true" tabindex="-1"></a>    df_copy[<span class="st">'VLM_Score'</span>] <span class="op">=</span> scores</span>
<span id="cb10-171"><a href="#cb10-171" aria-hidden="true" tabindex="-1"></a>    df_copy[<span class="st">'VLM_Response'</span>] <span class="op">=</span> responses</span>
<span id="cb10-172"><a href="#cb10-172" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-173"><a href="#cb10-173" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> df_copy</span>
<span id="cb10-174"><a href="#cb10-174" aria-hidden="true" tabindex="-1"></a></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Loaded 12 unergative scenes
Loaded 12 unaccusative scenes</code></pre>
</div>
</div>
<div id="cell-8" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="f1e38090-f094-45db-edb9-5aff227b8011" data-execution_count="29">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ============================================================================</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Run Analysis</span></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="co"># ============================================================================</span></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> os.path.exists(CACHE_FILE):</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Loading cached scores from </span><span class="sc">{</span>CACHE_FILE<span class="sc">}</span><span class="ss">..."</span>)</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>    df_all <span class="op">=</span> pd.read_csv(CACHE_FILE)</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span><span class="op">*</span><span class="dv">60</span>)</span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Computing scores (this may take a few minutes)..."</span>)</span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"="</span><span class="op">*</span><span class="dv">60</span>)</span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># </span><span class="al">TEST</span><span class="co"> MODE: Use only first item from each dataset for quick verification</span></span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> TEST_MODE:</span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"⚠️  TEST MODE: Processing only 1 item from each verb type"</span>)</span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a>        df_unerg_test <span class="op">=</span> df_unerg.head(<span class="dv">1</span>)</span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a>        df_unacc_test <span class="op">=</span> df_unacc.head(<span class="dv">1</span>)</span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a>        df_unerg_test <span class="op">=</span> df_unerg</span>
<span id="cb12-20"><a href="#cb12-20" aria-hidden="true" tabindex="-1"></a>        df_unacc_test <span class="op">=</span> df_unacc</span>
<span id="cb12-21"><a href="#cb12-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-22"><a href="#cb12-22" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Compute CLIP similarities</span></span>
<span id="cb12-23"><a href="#cb12-23" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">📊 Computing CLIP full sentence similarities..."</span>)</span>
<span id="cb12-24"><a href="#cb12-24" aria-hidden="true" tabindex="-1"></a>    df_unerg_clip <span class="op">=</span> compute_clip_similarity(df_unerg_test, model_clip, preprocess, device)</span>
<span id="cb12-25"><a href="#cb12-25" aria-hidden="true" tabindex="-1"></a>    df_unacc_clip <span class="op">=</span> compute_clip_similarity(df_unacc_test, model_clip, preprocess, device)</span>
<span id="cb12-26"><a href="#cb12-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-27"><a href="#cb12-27" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Compute subject salience scores</span></span>
<span id="cb12-28"><a href="#cb12-28" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">📊 Computing subject salience scores..."</span>)</span>
<span id="cb12-29"><a href="#cb12-29" aria-hidden="true" tabindex="-1"></a>    df_unerg_subj <span class="op">=</span> compute_subject_salience(df_unerg_test, model_clip, preprocess, device)</span>
<span id="cb12-30"><a href="#cb12-30" aria-hidden="true" tabindex="-1"></a>    df_unacc_subj <span class="op">=</span> compute_subject_salience(df_unacc_test, model_clip, preprocess, device)</span>
<span id="cb12-31"><a href="#cb12-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-32"><a href="#cb12-32" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Compute Qwen-VL scores</span></span>
<span id="cb12-33"><a href="#cb12-33" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">🤖 Computing VLM scores for unergative items..."</span>)</span>
<span id="cb12-34"><a href="#cb12-34" aria-hidden="true" tabindex="-1"></a>    df_unerg_vlm <span class="op">=</span> compute_qwen_scores(df_unerg_test, model_vlm, tokenizer_vlm)</span>
<span id="cb12-35"><a href="#cb12-35" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">🤖 Computing VLM scores for unaccusative items..."</span>)</span>
<span id="cb12-36"><a href="#cb12-36" aria-hidden="true" tabindex="-1"></a>    df_unacc_vlm <span class="op">=</span> compute_qwen_scores(df_unacc_test, model_vlm, tokenizer_vlm)</span>
<span id="cb12-37"><a href="#cb12-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-38"><a href="#cb12-38" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Combine all scores</span></span>
<span id="cb12-39"><a href="#cb12-39" aria-hidden="true" tabindex="-1"></a>    df_unerg_scored <span class="op">=</span> df_unerg_clip.copy()</span>
<span id="cb12-40"><a href="#cb12-40" aria-hidden="true" tabindex="-1"></a>    df_unerg_scored[<span class="st">'Subject_Salience'</span>] <span class="op">=</span> df_unerg_subj[<span class="st">'Subject_Salience'</span>]</span>
<span id="cb12-41"><a href="#cb12-41" aria-hidden="true" tabindex="-1"></a>    df_unerg_scored[<span class="st">'VLM_Score'</span>] <span class="op">=</span> df_unerg_vlm[<span class="st">'VLM_Score'</span>]</span>
<span id="cb12-42"><a href="#cb12-42" aria-hidden="true" tabindex="-1"></a>    df_unerg_scored[<span class="st">'VLM_Response'</span>] <span class="op">=</span> df_unerg_vlm[<span class="st">'VLM_Response'</span>]</span>
<span id="cb12-43"><a href="#cb12-43" aria-hidden="true" tabindex="-1"></a>    df_unerg_scored[<span class="st">'VerbType'</span>] <span class="op">=</span> <span class="st">'Unergative'</span></span>
<span id="cb12-44"><a href="#cb12-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-45"><a href="#cb12-45" aria-hidden="true" tabindex="-1"></a>    df_unacc_scored <span class="op">=</span> df_unacc_clip.copy()</span>
<span id="cb12-46"><a href="#cb12-46" aria-hidden="true" tabindex="-1"></a>    df_unacc_scored[<span class="st">'Subject_Salience'</span>] <span class="op">=</span> df_unacc_subj[<span class="st">'Subject_Salience'</span>]</span>
<span id="cb12-47"><a href="#cb12-47" aria-hidden="true" tabindex="-1"></a>    df_unacc_scored[<span class="st">'VLM_Score'</span>] <span class="op">=</span> df_unacc_vlm[<span class="st">'VLM_Score'</span>]</span>
<span id="cb12-48"><a href="#cb12-48" aria-hidden="true" tabindex="-1"></a>    df_unacc_scored[<span class="st">'VLM_Response'</span>] <span class="op">=</span> df_unacc_vlm[<span class="st">'VLM_Response'</span>]</span>
<span id="cb12-49"><a href="#cb12-49" aria-hidden="true" tabindex="-1"></a>    df_unacc_scored[<span class="st">'VerbType'</span>] <span class="op">=</span> <span class="st">'Unaccusative'</span></span>
<span id="cb12-50"><a href="#cb12-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-51"><a href="#cb12-51" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Combine for analysis</span></span>
<span id="cb12-52"><a href="#cb12-52" aria-hidden="true" tabindex="-1"></a>    df_all <span class="op">=</span> pd.concat([df_unerg_scored, df_unacc_scored], ignore_index<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb12-53"><a href="#cb12-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-54"><a href="#cb12-54" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Save to cache</span></span>
<span id="cb12-55"><a href="#cb12-55" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> TEST_MODE:</span>
<span id="cb12-56"><a href="#cb12-56" aria-hidden="true" tabindex="-1"></a>        df_all.to_csv(CACHE_FILE, index<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb12-57"><a href="#cb12-57" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">✓ Scores cached to </span><span class="sc">{</span>CACHE_FILE<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb12-58"><a href="#cb12-58" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb12-59"><a href="#cb12-59" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">⚠️  TEST MODE: Results not cached. Set TEST_MODE=False to cache full results."</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Loading cached scores from ./cached_scores.csv...</code></pre>
</div>
</div>
<div id="cell-9" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="91bc0eb1-45c2-474f-cf67-0c6458e83e42" data-execution_count="30">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="co"># ============================================================================</span></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Print Results</span></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a><span class="co"># ============================================================================</span></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span><span class="op">*</span><span class="dv">60</span>)</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"RESULTS SUMMARY"</span>)</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span><span class="op">*</span><span class="dv">60</span>)</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st"> CLIP Full Sentence Similarity:"</span>)</span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Unergative mean:   </span><span class="sc">{</span>df_all[df_all[<span class="st">'VerbType'</span>]<span class="op">==</span><span class="st">'Unergative'</span>][<span class="st">'CLIP_Similarity'</span>]<span class="sc">.</span>mean()<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Unaccusative mean: </span><span class="sc">{</span>df_all[df_all[<span class="st">'VerbType'</span>]<span class="op">==</span><span class="st">'Unaccusative'</span>][<span class="st">'CLIP_Similarity'</span>]<span class="sc">.</span>mean()<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st"> Subject Salience (Subject Noun Only):"</span>)</span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Unergative mean:   </span><span class="sc">{</span>df_all[df_all[<span class="st">'VerbType'</span>]<span class="op">==</span><span class="st">'Unergative'</span>][<span class="st">'Subject_Salience'</span>]<span class="sc">.</span>mean()<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Unaccusative mean: </span><span class="sc">{</span>df_all[df_all[<span class="st">'VerbType'</span>]<span class="op">==</span><span class="st">'Unaccusative'</span>][<span class="st">'Subject_Salience'</span>]<span class="sc">.</span>mean()<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st"> Qwen-VL-Chat Match Ratings:"</span>)</span>
<span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Unergative mean:   </span><span class="sc">{</span>df_all[df_all[<span class="st">'VerbType'</span>]<span class="op">==</span><span class="st">'Unergative'</span>][<span class="st">'VLM_Score'</span>]<span class="sc">.</span>mean()<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb14-20"><a href="#cb14-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Unaccusative mean: </span><span class="sc">{</span>df_all[df_all[<span class="st">'VerbType'</span>]<span class="op">==</span><span class="st">'Unaccusative'</span>][<span class="st">'VLM_Score'</span>]<span class="sc">.</span>mean()<span class="sc">:.2f}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>
============================================================
RESULTS SUMMARY
============================================================

 CLIP Full Sentence Similarity:
  Unergative mean:   27.76
  Unaccusative mean: 25.39

 Subject Salience (Subject Noun Only):
  Unergative mean:   27.44
  Unaccusative mean: 25.95

 Qwen-VL-Chat Match Ratings:
  Unergative mean:   7.17
  Unaccusative mean: 4.75</code></pre>
</div>
</div>
<div id="cell-10" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:1000}}" data-outputid="6a71b245-6929-49ae-c952-b7c9909adc9c" data-execution_count="31">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="co"># ============================================================================</span></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualizations</span></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a><span class="co"># ============================================================================</span></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">📊 Creating visualizations..."</span>)</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Create comparison plot with all three metrics</span></span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">3</span>, figsize<span class="op">=</span>(<span class="dv">20</span>, <span class="dv">6</span>))</span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a><span class="co"># CLIP full sentence results</span></span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a>sns.pointplot(data<span class="op">=</span>df_all, x<span class="op">=</span><span class="st">'VerbType'</span>, y<span class="op">=</span><span class="st">'CLIP_Similarity'</span>,</span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a>              palette<span class="op">=</span>[<span class="st">'#3498db'</span>, <span class="st">'#e74c3c'</span>], ax<span class="op">=</span>axes[<span class="dv">0</span>], errorbar<span class="op">=</span><span class="st">'ci'</span>, capsize<span class="op">=</span><span class="fl">0.1</span>, join<span class="op">=</span><span class="va">False</span>, markers<span class="op">=</span><span class="st">'o'</span>)</span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a>sns.stripplot(data<span class="op">=</span>df_all, x<span class="op">=</span><span class="st">'VerbType'</span>, y<span class="op">=</span><span class="st">'CLIP_Similarity'</span>,</span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a>              color<span class="op">=</span><span class="st">'black'</span>, alpha<span class="op">=</span><span class="fl">0.5</span>, size<span class="op">=</span><span class="dv">8</span>, ax<span class="op">=</span>axes[<span class="dv">0</span>], jitter<span class="op">=</span><span class="fl">0.2</span>)</span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_xlabel(<span class="st">'Verb Type'</span>, fontsize<span class="op">=</span><span class="dv">14</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_ylabel(<span class="st">'CLIP Similarity Score'</span>, fontsize<span class="op">=</span><span class="dv">14</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_title(<span class="st">'Full Sentence Similarity'</span>,</span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a>                  fontsize<span class="op">=</span><span class="dv">16</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>, pad<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-22"><a href="#cb16-22" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> verb_type <span class="kw">in</span> [<span class="st">'Unergative'</span>, <span class="st">'Unaccusative'</span>]:</span>
<span id="cb16-23"><a href="#cb16-23" aria-hidden="true" tabindex="-1"></a>    mean_val <span class="op">=</span> df_all[df_all[<span class="st">'VerbType'</span>] <span class="op">==</span> verb_type][<span class="st">'CLIP_Similarity'</span>].mean()</span>
<span id="cb16-24"><a href="#cb16-24" aria-hidden="true" tabindex="-1"></a>    axes[<span class="dv">0</span>].text(<span class="dv">0</span> <span class="cf">if</span> verb_type <span class="op">==</span> <span class="st">'Unergative'</span> <span class="cf">else</span> <span class="dv">1</span>, mean_val <span class="op">+</span> <span class="dv">1</span>,</span>
<span id="cb16-25"><a href="#cb16-25" aria-hidden="true" tabindex="-1"></a>                 <span class="ss">f'M = </span><span class="sc">{</span>mean_val<span class="sc">:.2f}</span><span class="ss">'</span>, ha<span class="op">=</span><span class="st">'center'</span>, fontsize<span class="op">=</span><span class="dv">12</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb16-26"><a href="#cb16-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-27"><a href="#cb16-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Subject salience results</span></span>
<span id="cb16-28"><a href="#cb16-28" aria-hidden="true" tabindex="-1"></a>sns.pointplot(data<span class="op">=</span>df_all, x<span class="op">=</span><span class="st">'VerbType'</span>, y<span class="op">=</span><span class="st">'Subject_Salience'</span>,</span>
<span id="cb16-29"><a href="#cb16-29" aria-hidden="true" tabindex="-1"></a>              palette<span class="op">=</span>[<span class="st">'#3498db'</span>, <span class="st">'#e74c3c'</span>], ax<span class="op">=</span>axes[<span class="dv">1</span>], errorbar<span class="op">=</span><span class="st">'ci'</span>, capsize<span class="op">=</span><span class="fl">0.1</span>, join<span class="op">=</span><span class="va">False</span>, markers<span class="op">=</span><span class="st">'o'</span>)</span>
<span id="cb16-30"><a href="#cb16-30" aria-hidden="true" tabindex="-1"></a>sns.stripplot(data<span class="op">=</span>df_all, x<span class="op">=</span><span class="st">'VerbType'</span>, y<span class="op">=</span><span class="st">'Subject_Salience'</span>,</span>
<span id="cb16-31"><a href="#cb16-31" aria-hidden="true" tabindex="-1"></a>              color<span class="op">=</span><span class="st">'black'</span>, alpha<span class="op">=</span><span class="fl">0.5</span>, size<span class="op">=</span><span class="dv">8</span>, ax<span class="op">=</span>axes[<span class="dv">1</span>], jitter<span class="op">=</span><span class="fl">0.2</span>)</span>
<span id="cb16-32"><a href="#cb16-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-33"><a href="#cb16-33" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_xlabel(<span class="st">'Verb Type'</span>, fontsize<span class="op">=</span><span class="dv">14</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb16-34"><a href="#cb16-34" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_ylabel(<span class="st">'Subject Salience Score'</span>, fontsize<span class="op">=</span><span class="dv">14</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb16-35"><a href="#cb16-35" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_title(<span class="st">'Subject Noun Identifiability'</span>,</span>
<span id="cb16-36"><a href="#cb16-36" aria-hidden="true" tabindex="-1"></a>                  fontsize<span class="op">=</span><span class="dv">16</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>, pad<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb16-37"><a href="#cb16-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-38"><a href="#cb16-38" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> verb_type <span class="kw">in</span> [<span class="st">'Unergative'</span>, <span class="st">'Unaccusative'</span>]:</span>
<span id="cb16-39"><a href="#cb16-39" aria-hidden="true" tabindex="-1"></a>    mean_val <span class="op">=</span> df_all[df_all[<span class="st">'VerbType'</span>] <span class="op">==</span> verb_type][<span class="st">'Subject_Salience'</span>].mean()</span>
<span id="cb16-40"><a href="#cb16-40" aria-hidden="true" tabindex="-1"></a>    axes[<span class="dv">1</span>].text(<span class="dv">0</span> <span class="cf">if</span> verb_type <span class="op">==</span> <span class="st">'Unergative'</span> <span class="cf">else</span> <span class="dv">1</span>, mean_val <span class="op">+</span> <span class="fl">0.5</span>,</span>
<span id="cb16-41"><a href="#cb16-41" aria-hidden="true" tabindex="-1"></a>                 <span class="ss">f'M = </span><span class="sc">{</span>mean_val<span class="sc">:.2f}</span><span class="ss">'</span>, ha<span class="op">=</span><span class="st">'center'</span>, fontsize<span class="op">=</span><span class="dv">12</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb16-42"><a href="#cb16-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-43"><a href="#cb16-43" aria-hidden="true" tabindex="-1"></a><span class="co"># Qwen-VL results</span></span>
<span id="cb16-44"><a href="#cb16-44" aria-hidden="true" tabindex="-1"></a>sns.pointplot(data<span class="op">=</span>df_all, x<span class="op">=</span><span class="st">'VerbType'</span>, y<span class="op">=</span><span class="st">'VLM_Score'</span>,</span>
<span id="cb16-45"><a href="#cb16-45" aria-hidden="true" tabindex="-1"></a>              palette<span class="op">=</span>[<span class="st">'#3498db'</span>, <span class="st">'#e74c3c'</span>], ax<span class="op">=</span>axes[<span class="dv">2</span>], errorbar<span class="op">=</span><span class="st">'ci'</span>, capsize<span class="op">=</span><span class="fl">0.1</span>, join<span class="op">=</span><span class="va">False</span>, markers<span class="op">=</span><span class="st">'o'</span>)</span>
<span id="cb16-46"><a href="#cb16-46" aria-hidden="true" tabindex="-1"></a>sns.stripplot(data<span class="op">=</span>df_all, x<span class="op">=</span><span class="st">'VerbType'</span>, y<span class="op">=</span><span class="st">'VLM_Score'</span>,</span>
<span id="cb16-47"><a href="#cb16-47" aria-hidden="true" tabindex="-1"></a>              color<span class="op">=</span><span class="st">'black'</span>, alpha<span class="op">=</span><span class="fl">0.5</span>, size<span class="op">=</span><span class="dv">8</span>, ax<span class="op">=</span>axes[<span class="dv">2</span>], jitter<span class="op">=</span><span class="fl">0.2</span>)</span>
<span id="cb16-48"><a href="#cb16-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-49"><a href="#cb16-49" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">2</span>].set_xlabel(<span class="st">'Verb Type'</span>, fontsize<span class="op">=</span><span class="dv">14</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb16-50"><a href="#cb16-50" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">2</span>].set_ylabel(<span class="st">'Qwen-VL Match Score (1-10)'</span>, fontsize<span class="op">=</span><span class="dv">14</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb16-51"><a href="#cb16-51" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">2</span>].set_title(<span class="st">'VLM Match Ratings'</span>,</span>
<span id="cb16-52"><a href="#cb16-52" aria-hidden="true" tabindex="-1"></a>                  fontsize<span class="op">=</span><span class="dv">16</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>, pad<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb16-53"><a href="#cb16-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-54"><a href="#cb16-54" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> verb_type <span class="kw">in</span> [<span class="st">'Unergative'</span>, <span class="st">'Unaccusative'</span>]:</span>
<span id="cb16-55"><a href="#cb16-55" aria-hidden="true" tabindex="-1"></a>    mean_val <span class="op">=</span> df_all[df_all[<span class="st">'VerbType'</span>] <span class="op">==</span> verb_type][<span class="st">'VLM_Score'</span>].mean()</span>
<span id="cb16-56"><a href="#cb16-56" aria-hidden="true" tabindex="-1"></a>    axes[<span class="dv">2</span>].text(<span class="dv">0</span> <span class="cf">if</span> verb_type <span class="op">==</span> <span class="st">'Unergative'</span> <span class="cf">else</span> <span class="dv">1</span>, mean_val <span class="op">+</span> <span class="fl">0.3</span>,</span>
<span id="cb16-57"><a href="#cb16-57" aria-hidden="true" tabindex="-1"></a>                 <span class="ss">f'M = </span><span class="sc">{</span>mean_val<span class="sc">:.2f}</span><span class="ss">'</span>, ha<span class="op">=</span><span class="st">'center'</span>, fontsize<span class="op">=</span><span class="dv">12</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb16-58"><a href="#cb16-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-59"><a href="#cb16-59" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb16-60"><a href="#cb16-60" aria-hidden="true" tabindex="-1"></a>plt.savefig(<span class="st">'model_comparison_plot.png'</span>, dpi<span class="op">=</span><span class="dv">300</span>, bbox_inches<span class="op">=</span><span class="st">'tight'</span>)</span>
<span id="cb16-61"><a href="#cb16-61" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"✓ Saved model_comparison_plot.png"</span>)</span>
<span id="cb16-62"><a href="#cb16-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-63"><a href="#cb16-63" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb16-64"><a href="#cb16-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-65"><a href="#cb16-65" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span><span class="op">*</span><span class="dv">60</span>)</span>
<span id="cb16-66"><a href="#cb16-66" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"✓ Analysis complete!"</span>)</span>
<span id="cb16-67"><a href="#cb16-67" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span><span class="op">*</span><span class="dv">60</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>
📊 Creating visualizations...</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/tmp/ipython-input-713175751.py:11: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.pointplot(data=df_all, x='VerbType', y='CLIP_Similarity',
/tmp/ipython-input-713175751.py:11: UserWarning: 

The `join` parameter is deprecated and will be removed in v0.15.0. You can remove the line between points with `linestyle='none'`.

  sns.pointplot(data=df_all, x='VerbType', y='CLIP_Similarity',
/tmp/ipython-input-713175751.py:27: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.pointplot(data=df_all, x='VerbType', y='Subject_Salience',
/tmp/ipython-input-713175751.py:27: UserWarning: 

The `join` parameter is deprecated and will be removed in v0.15.0. You can remove the line between points with `linestyle='none'`.

  sns.pointplot(data=df_all, x='VerbType', y='Subject_Salience',
/tmp/ipython-input-713175751.py:43: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.pointplot(data=df_all, x='VerbType', y='VLM_Score',
/tmp/ipython-input-713175751.py:43: UserWarning: 

The `join` parameter is deprecated and will be removed in v0.15.0. You can remove the line between points with `linestyle='none'`.

  sns.pointplot(data=df_all, x='VerbType', y='VLM_Score',</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>✓ Saved model_comparison_plot.png</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="clip_analysis_files/figure-html/cell-9-output-4.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
============================================================
✓ Analysis complete!
============================================================</code></pre>
</div>
</div>
</section>
<section id="summary" class="level2">
<h2 class="anchored" data-anchor-id="summary">Summary:</h2>
<section id="data-analysis-key-findings" class="level3">
<h3 class="anchored" data-anchor-id="data-analysis-key-findings">Data Analysis Key Findings</h3>
<ul>
<li><strong>Data Preparation</strong>: The data was successfully prepared for PyMC3 modeling by extracting ‘CLIP_Similarity’, ‘Subject_Salience’, ‘VLM_Score’, and ‘VerbType’. ‘VerbType’ was numerically encoded (Unergative: 0, Unaccusative: 1), and continuous variables were scaled using <code>MinMaxScaler</code>.</li>
<li><strong>CLIP Similarity Model</strong>:
<ul>
<li>The <code>beta</code> parameter, representing the effect of <code>VerbType</code> on <code>CLIP_Similarity</code>, had a mean of -0.164.</li>
<li>The 94% Highest Posterior Density (HPD) interval for <code>beta</code> was [-0.370, 0.022].</li>
<li>The negative mean suggests lower CLIP similarity for Unaccusative scenes compared to Unergative scenes, but the HPD interval crossing zero indicates this difference is not statistically significant.</li>
</ul></li>
<li><strong>Subject Salience Model</strong>:
<ul>
<li>The <code>beta</code> parameter for the effect of <code>VerbType</code> on <code>Subject_Salience</code> had a mean of -0.100.</li>
<li>Its 94% HPD interval was [-0.311, 0.130].</li>
<li>A negative mean suggests lower subject salience for Unaccusative scenes, but the HPD interval crossing zero indicates this difference is not statistically significant.</li>
</ul></li>
<li><strong>VLM Score Model</strong>:
<ul>
<li>The <code>beta</code> parameter for the effect of <code>VerbType</code> on the latent propensity for <code>VLM_Score</code> had a mean of -0.830.</li>
<li>Its 94% HPD interval was [-1.854, 0.167].</li>
<li>The negative mean suggests that Unaccusative scenes are associated with a lower latent propensity for higher VLM scores, but the HPD interval crossing zero indicates this difference is not statistically significant.</li>
</ul></li>
<li><strong>Overall Comparison</strong>: For all three metrics (CLIP Similarity, Subject Salience, and VLM Score), the Bayesian regression models suggest a general tendency for unaccusative verbs to be associated with lower scores compared to unergative verbs (indicated by negative <code>beta</code> means). However, these observed differences are not statistically significant at the 94% HPD level for any of the models, as their respective credible intervals for the <code>beta</code> parameter all include zero.</li>
</ul>
</section>
<section id="insights-or-next-steps" class="level3">
<h3 class="anchored" data-anchor-id="insights-or-next-steps">Insights or Next Steps</h3>
<ul>
<li><strong>Investigate Data Variability</strong>: Although the models indicate a directional trend (unaccusative scenes tending towards lower scores), the lack of statistical significance suggests high variability within the data or insufficient sample size to detect a clear difference. Further data collection or exploration of other covariates might be beneficial.</li>
<li><strong>Explore Alternative Model Specifications</strong>: Consider alternative model structures or priors, or even hierarchical models if there are grouping factors in the data, to see if a more nuanced understanding of the <code>VerbType</code> effect can be achieved.</li>
</ul>
</section>
</section>
<section id="task" class="level1">
<h1>Task</h1>
<p>Perform a Bayesian analysis using Pyro to investigate the effect of ‘VerbType’ on ‘CLIP_Similarity’, ‘Subject_Salience’, and ‘VLM_Score’. Prepare a new DataFrame, <code>df_pyro</code>, by encoding ‘VerbType’ (Unergative: -0.5, Unaccusative: 0.5), mean-centering ‘CLIP_Similarity’ and ‘Subject_Salience’, and ensuring ‘VLM_Score’ is an integer. Define and analyze three separate Bayesian models: a linear regression for ‘CLIP_Similarity’, a linear regression for ‘Subject_Salience’, and an ordered logistic regression for ‘VLM_Score’, each using ‘VerbType’ as the primary predictor and NUTS for inference. For each model, visualize the posterior distributions of the intercept and ‘VerbType’ coefficient, and calculate the probability of the ‘VerbType’ coefficient being less than or greater than zero. Finally, summarize the key findings from all three models, highlighting the impact of ‘VerbType’ on the respective outcomes, along with their associated probabilities and credible intervals.</p>
<section id="prepare-data-for-pyro" class="level2">
<h2 class="anchored" data-anchor-id="prepare-data-for-pyro">Prepare Data for Pyro</h2>
<section id="subtask" class="level3">
<h3 class="anchored" data-anchor-id="subtask">Subtask:</h3>
<p>Create a new DataFrame, <code>df_pyro</code>, based on <code>df_all</code>. Encode ‘VerbType’ to numerical values (-0.5 for Unergative, 0.5 for Unaccusative) as the main predictor. Mean-center ‘CLIP_Similarity’ and ‘Subject_Salience’. Convert ‘VLM_Score’ to integer type if it isn’t already.</p>
<p><strong>Reasoning</strong>: To prepare the data for Pyro modeling as instructed, I will create a copy of <code>df_all</code>, encode the ‘VerbType’ column numerically, mean-center the ‘CLIP_Similarity’ and ‘Subject_Salience’ columns, and convert the ‘VLM_Score’ column to integer type.</p>
<div id="cell-15" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="b75201fb-07f2-4408-e74c-34db9da336ac" data-execution_count="32">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>df_pyro <span class="op">=</span> df_all.copy()</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>df_pyro[<span class="st">'VerbType'</span>] <span class="op">=</span> df_pyro[<span class="st">'VerbType'</span>].<span class="bu">map</span>({<span class="st">'Unergative'</span>: <span class="op">-</span><span class="fl">0.5</span>, <span class="st">'Unaccusative'</span>: <span class="fl">0.5</span>})</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>df_pyro[<span class="st">'CLIP_Similarity'</span>] <span class="op">=</span> df_pyro[<span class="st">'CLIP_Similarity'</span>] <span class="op">-</span> df_pyro[<span class="st">'CLIP_Similarity'</span>].mean()</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>df_pyro[<span class="st">'Subject_Salience'</span>] <span class="op">=</span> df_pyro[<span class="st">'Subject_Salience'</span>] <span class="op">-</span> df_pyro[<span class="st">'Subject_Salience'</span>].mean()</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>df_pyro[<span class="st">'VLM_Score'</span>] <span class="op">=</span> df_pyro[<span class="st">'VLM_Score'</span>].astype(<span class="bu">int</span>)</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"df_pyro created and prepared for Pyro modeling:"</span>)</span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df_pyro.head())</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>df_pyro created and prepared for Pyro modeling:
              Filename                   Sentence  CLIP_Similarity  \
0   ./octopus_swim.jpg   The octopus is swimming.         2.562173   
1  ./ballerina_run.jpg  The ballerina is running.         1.156596   
2      ./boy_float.jpg       The boy is floating.        -5.732079   
3      ./chef_yell.jpg       The chef is yelling.         1.303239   
4     ./clown_walk.jpg      The clown is walking.         0.502155   

   Subject_Salience  VLM_Score  VLM_Response  VerbType  
0          1.759763          8             8      -0.5  
1         -1.444149          7             7      -0.5  
2         -5.066134          1             1      -0.5  
3          1.795364          8             8      -0.5  
4         -0.453623          8             8      -0.5  </code></pre>
</div>
</div>
<p><strong>Reasoning</strong>: Now that the data is prepared, I will proceed to define and analyze the first Bayesian model, a linear regression for ‘CLIP_Similarity’ using ‘VerbType’ as a predictor, which requires importing Pyro libraries and setting up the model for inference.</p>
<div id="cell-17" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:1000,&quot;referenced_widgets&quot;:[&quot;226e0b89bf374075a82742545abd6179&quot;,&quot;fcd891dc283d42f0a0df5c32920f47aa&quot;,&quot;b120b43bc3cb485ead2d3d9eff7182b3&quot;,&quot;192e4a955f404dbc97b26d3111b56807&quot;,&quot;8a55026abda54a2280eba6b00ca157e2&quot;,&quot;f7fad5830f6c4335af43a59e1fffee32&quot;,&quot;625844de5cf0476598ea3ac863b86990&quot;,&quot;81a45085d4194190bc481986022e787a&quot;,&quot;605552bf9c354f19ae2f740afba774f0&quot;,&quot;b06bc9bc31174c1f9cb36daf578e875c&quot;,&quot;c64be3069b514b1dbc4011ac52c85f09&quot;,&quot;f7d4d1a44b8945c6858855e5bac80f68&quot;,&quot;eddc14c45c44419ebbc9a27f7030c5c8&quot;,&quot;813b105293bf48b0a8f34284ae82f01a&quot;,&quot;497af76d7b664c08a0ba92b9fc66a3b0&quot;,&quot;0e02de5057ea4275b350c33860310e16&quot;,&quot;234d8d4896d64d7fb82a2cd7bcb7604b&quot;,&quot;b00ac42329a741928c922edba0316ccd&quot;,&quot;9ef1ce6653664072bbd732fa85357b41&quot;,&quot;85bbd6683b81407abbfeb6f3895a4892&quot;,&quot;cc0af601364d42b3bfa4bf6d2764e3ce&quot;,&quot;15cba173b20645869ed2d2226c1942bf&quot;]}}" data-outputid="e97ab05b-eb25-4340-d0d2-9d0af68d39b5" data-execution_count="33">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pyro</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pyro.distributions <span class="im">as</span> dist</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pyro.infer <span class="im">as</span> infer</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyro.infer.mcmc <span class="im">import</span> MCMC, NUTS</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Set random seed for reproducibility</span></span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a>pyro.set_rng_seed(<span class="dv">1</span>)</span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert relevant columns to PyTorch tensors</span></span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a>clip_similarity_data <span class="op">=</span> torch.tensor(df_pyro[<span class="st">'CLIP_Similarity'</span>].values, dtype<span class="op">=</span>torch.float32)</span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a>verb_type_encoded <span class="op">=</span> torch.tensor(df_pyro[<span class="st">'VerbType'</span>].values, dtype<span class="op">=</span>torch.float32)</span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the linear regression model for CLIP_Similarity</span></span>
<span id="cb23-14"><a href="#cb23-14" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> model_clip_similarity(verb_type_encoded, obs_data<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb23-15"><a href="#cb23-15" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Priors for the intercept and the coefficient for VerbType</span></span>
<span id="cb23-16"><a href="#cb23-16" aria-hidden="true" tabindex="-1"></a>    alpha <span class="op">=</span> pyro.sample(<span class="st">'alpha'</span>, dist.Normal(<span class="fl">0.</span>, <span class="fl">10.</span>))</span>
<span id="cb23-17"><a href="#cb23-17" aria-hidden="true" tabindex="-1"></a>    beta <span class="op">=</span> pyro.sample(<span class="st">'beta'</span>, dist.Normal(<span class="fl">0.</span>, <span class="fl">10.</span>))</span>
<span id="cb23-18"><a href="#cb23-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-19"><a href="#cb23-19" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Linear predictor</span></span>
<span id="cb23-20"><a href="#cb23-20" aria-hidden="true" tabindex="-1"></a>    mu <span class="op">=</span> alpha <span class="op">+</span> beta <span class="op">*</span> verb_type_encoded</span>
<span id="cb23-21"><a href="#cb23-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-22"><a href="#cb23-22" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Observation likelihood</span></span>
<span id="cb23-23"><a href="#cb23-23" aria-hidden="true" tabindex="-1"></a>    sigma <span class="op">=</span> pyro.sample(<span class="st">'sigma'</span>, dist.HalfCauchy(<span class="fl">1.</span>))</span>
<span id="cb23-24"><a href="#cb23-24" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> pyro.plate(<span class="st">'data'</span>, <span class="bu">len</span>(verb_type_encoded)):</span>
<span id="cb23-25"><a href="#cb23-25" aria-hidden="true" tabindex="-1"></a>        pyro.sample(<span class="st">'obs'</span>, dist.Normal(mu, sigma), obs<span class="op">=</span>obs_data)</span>
<span id="cb23-26"><a href="#cb23-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-27"><a href="#cb23-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Set up NUTS sampler</span></span>
<span id="cb23-28"><a href="#cb23-28" aria-hidden="true" tabindex="-1"></a>kernel <span class="op">=</span> NUTS(model_clip_similarity)</span>
<span id="cb23-29"><a href="#cb23-29" aria-hidden="true" tabindex="-1"></a>mcmc_clip <span class="op">=</span> MCMC(kernel, num_samples<span class="op">=</span><span class="dv">1000</span>, warmup_steps<span class="op">=</span><span class="dv">500</span>, num_chains<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb23-30"><a href="#cb23-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-31"><a href="#cb23-31" aria-hidden="true" tabindex="-1"></a><span class="co"># Run inference</span></span>
<span id="cb23-32"><a href="#cb23-32" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Running MCMC for CLIP Similarity model..."</span>)</span>
<span id="cb23-33"><a href="#cb23-33" aria-hidden="true" tabindex="-1"></a>mcmc_clip.run(verb_type_encoded, obs_data<span class="op">=</span>clip_similarity_data)</span>
<span id="cb23-34"><a href="#cb23-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-35"><a href="#cb23-35" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"MCMC for CLIP Similarity model complete."</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Running MCMC for CLIP Similarity model...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"version_major":2,"version_minor":0,"model_id":"226e0b89bf374075a82742545abd6179","quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"version_major":2,"version_minor":0,"model_id":"f7d4d1a44b8945c6858855e5bac80f68","quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>[ERROR LOG CHAIN:0]Unable to handle autograd's threading in combination with fork-based multiprocessing. See https://github.com/pytorch/pytorch/wiki/Autograd-and-Fork
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/dist-packages/pyro/infer/mcmc/api.py", line 127, in run
    for sample in _gen_samples(
                  ^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/pyro/infer/mcmc/api.py", line 146, in _gen_samples
    kernel.setup(warmup_steps, *args, **kwargs)
  File "/usr/local/lib/python3.12/dist-packages/pyro/infer/mcmc/hmc.py", line 345, in setup
    self._initialize_model_properties(args, kwargs)
  File "/usr/local/lib/python3.12/dist-packages/pyro/infer/mcmc/hmc.py", line 279, in _initialize_model_properties
    init_params, potential_fn, transforms, trace = initialize_model(
                                                   ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/pyro/infer/mcmc/util.py", line 468, in initialize_model
    initial_params = _find_valid_initial_params(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/pyro/infer/mcmc/util.py", line 351, in _find_valid_initial_params
    pe_grad, pe = potential_grad(potential_fn, params)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/pyro/ops/integrator.py", line 91, in potential_grad
    grads = grad(potential_energy, z_nodes)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/autograd/__init__.py", line 452, in grad
    return handle_torch_function(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/overrides.py", line 1728, in handle_torch_function
    result = mode.__torch_function__(public_api, types, args, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/autograd/__init__.py", line 503, in grad
    result = _engine_run_backward(
             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Unable to handle autograd's threading in combination with fork-based multiprocessing. See https://github.com/pytorch/pytorch/wiki/Autograd-and-Fork
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/dist-packages/pyro/infer/mcmc/api.py", line 127, in run
    for sample in _gen_samples(
                  ^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/pyro/infer/mcmc/api.py", line 146, in _gen_samples
    kernel.setup(warmup_steps, *args, **kwargs)
  File "/usr/local/lib/python3.12/dist-packages/pyro/infer/mcmc/hmc.py", line 345, in setup
    self._initialize_model_properties(args, kwargs)
  File "/usr/local/lib/python3.12/dist-packages/pyro/infer/mcmc/hmc.py", line 279, in _initialize_model_properties
    init_params, potential_fn, transforms, trace = initialize_model(
                                                   ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/pyro/infer/mcmc/util.py", line 468, in initialize_model
    initial_params = _find_valid_initial_params(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/pyro/infer/mcmc/util.py", line 351, in _find_valid_initial_params
    pe_grad, pe = potential_grad(potential_fn, params)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/pyro/ops/integrator.py", line 91, in potential_grad
    grads = grad(potential_energy, z_nodes)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/autograd/__init__.py", line 452, in grad
    return handle_torch_function(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/overrides.py", line 1728, in handle_torch_function
    result = mode.__torch_function__(public_api, types, args, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/autograd/__init__.py", line 503, in grad
    result = _engine_run_backward(
             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Unable to handle autograd's threading in combination with fork-based multiprocessing. See https://github.com/pytorch/pytorch/wiki/Autograd-and-Fork</code></pre>
</div>
<div class="cell-output cell-output-error">
<div class="ansi-escaped-output">
<pre><span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">RuntimeError</span>                              Traceback (most recent call last)
<span class="ansi-green-fg">/tmp/ipython-input-3403599407.py</span> in <span class="ansi-cyan-fg">&lt;cell line: 0&gt;</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-fg ansi-bold">     31</span> <span class="ansi-red-fg"># Run inference</span>
<span class="ansi-green-fg ansi-bold">     32</span> print<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">"\nRunning MCMC for CLIP Similarity model..."</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">---&gt; 33</span><span class="ansi-red-fg"> </span>mcmc_clip<span class="ansi-blue-fg">.</span>run<span class="ansi-blue-fg">(</span>verb_type_encoded<span class="ansi-blue-fg">,</span> obs_data<span class="ansi-blue-fg">=</span>clip_similarity_data<span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg ansi-bold">     34</span> 
<span class="ansi-green-fg ansi-bold">     35</span> print<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">"MCMC for CLIP Similarity model complete."</span><span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">/usr/local/lib/python3.12/dist-packages/pyro/poutine/messenger.py</span> in <span class="ansi-cyan-fg">_context_wrap</span><span class="ansi-blue-fg">(context, fn, *args, **kwargs)</span>
<span class="ansi-green-fg ansi-bold">     30</span> ) -&gt; Any:
<span class="ansi-green-fg ansi-bold">     31</span>     <span class="ansi-green-fg">with</span> context<span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">---&gt; 32</span><span class="ansi-red-fg">         </span><span class="ansi-green-fg">return</span> fn<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg ansi-bold">     33</span> 
<span class="ansi-green-fg ansi-bold">     34</span> 

<span class="ansi-green-fg">/usr/local/lib/python3.12/dist-packages/pyro/infer/mcmc/api.py</span> in <span class="ansi-cyan-fg">run</span><span class="ansi-blue-fg">(self, *args, **kwargs)</span>
<span class="ansi-green-fg ansi-bold">    563</span>             <span class="ansi-red-fg"># requires_grad", which happens with `jit_compile` under PyTorch 1.7</span>
<span class="ansi-green-fg ansi-bold">    564</span>             args <span class="ansi-blue-fg">=</span> <span class="ansi-blue-fg">[</span>arg<span class="ansi-blue-fg">.</span>detach<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span> <span class="ansi-green-fg">if</span> torch<span class="ansi-blue-fg">.</span>is_tensor<span class="ansi-blue-fg">(</span>arg<span class="ansi-blue-fg">)</span> <span class="ansi-green-fg">else</span> arg <span class="ansi-green-fg">for</span> arg <span class="ansi-green-fg">in</span> args<span class="ansi-blue-fg">]</span>
<span class="ansi-green-fg">--&gt; 565</span><span class="ansi-red-fg">             </span><span class="ansi-green-fg">for</span> x<span class="ansi-blue-fg">,</span> chain_id <span class="ansi-green-fg">in</span> self<span class="ansi-blue-fg">.</span>sampler<span class="ansi-blue-fg">.</span>run<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg ansi-bold">    566</span>                 <span class="ansi-green-fg">if</span> num_samples<span class="ansi-blue-fg">[</span>chain_id<span class="ansi-blue-fg">]</span> <span class="ansi-blue-fg">==</span> <span class="ansi-cyan-fg">0</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg ansi-bold">    567</span>                     num_samples<span class="ansi-blue-fg">[</span>chain_id<span class="ansi-blue-fg">]</span> <span class="ansi-blue-fg">+=</span> <span class="ansi-cyan-fg">1</span>

<span class="ansi-green-fg">/usr/local/lib/python3.12/dist-packages/pyro/infer/mcmc/api.py</span> in <span class="ansi-cyan-fg">run</span><span class="ansi-blue-fg">(self, *args, **kwargs)</span>
<span class="ansi-green-fg ansi-bold">    341</span>                 <span class="ansi-green-fg">if</span> isinstance<span class="ansi-blue-fg">(</span>val<span class="ansi-blue-fg">,</span> Exception<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg ansi-bold">    342</span>                     <span class="ansi-red-fg"># Exception trace is already logged by worker.</span>
<span class="ansi-green-fg">--&gt; 343</span><span class="ansi-red-fg">                     </span><span class="ansi-green-fg">raise</span> val
<span class="ansi-green-fg ansi-bold">    344</span>                 <span class="ansi-green-fg">if</span> val <span class="ansi-green-fg">is</span> <span class="ansi-green-fg">not</span> <span class="ansi-green-fg">None</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg ansi-bold">    345</span>                     <span class="ansi-green-fg">yield</span> val<span class="ansi-blue-fg">,</span> chain_id

<span class="ansi-green-fg">/usr/local/lib/python3.12/dist-packages/pyro/infer/mcmc/api.py</span> in <span class="ansi-cyan-fg">run</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-fg ansi-bold">    125</span> 
<span class="ansi-green-fg ansi-bold">    126</span>         <span class="ansi-green-fg">try</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 127</span><span class="ansi-red-fg">             for sample in _gen_samples(
</span><span class="ansi-green-fg ansi-bold">    128</span>                 self<span class="ansi-blue-fg">.</span>kernel<span class="ansi-blue-fg">,</span>
<span class="ansi-green-fg ansi-bold">    129</span>                 self<span class="ansi-blue-fg">.</span>warmup_steps<span class="ansi-blue-fg">,</span>

<span class="ansi-green-fg">/usr/local/lib/python3.12/dist-packages/pyro/infer/mcmc/api.py</span> in <span class="ansi-cyan-fg">_gen_samples</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-fg ansi-bold">    144</span> 
<span class="ansi-green-fg ansi-bold">    145</span> <span class="ansi-green-fg">def</span> _gen_samples<span class="ansi-blue-fg">(</span>kernel<span class="ansi-blue-fg">,</span> warmup_steps<span class="ansi-blue-fg">,</span> num_samples<span class="ansi-blue-fg">,</span> hook<span class="ansi-blue-fg">,</span> chain_id<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 146</span><span class="ansi-red-fg">     </span>kernel<span class="ansi-blue-fg">.</span>setup<span class="ansi-blue-fg">(</span>warmup_steps<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg ansi-bold">    147</span>     params <span class="ansi-blue-fg">=</span> kernel<span class="ansi-blue-fg">.</span>initial_params
<span class="ansi-green-fg ansi-bold">    148</span>     save_params <span class="ansi-blue-fg">=</span> getattr<span class="ansi-blue-fg">(</span>kernel<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">"save_params"</span><span class="ansi-blue-fg">,</span> sorted<span class="ansi-blue-fg">(</span>params<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">/usr/local/lib/python3.12/dist-packages/pyro/infer/mcmc/hmc.py</span> in <span class="ansi-cyan-fg">setup</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-fg ansi-bold">    343</span>         self<span class="ansi-blue-fg">.</span>_warmup_steps <span class="ansi-blue-fg">=</span> warmup_steps
<span class="ansi-green-fg ansi-bold">    344</span>         <span class="ansi-green-fg">if</span> self<span class="ansi-blue-fg">.</span>model <span class="ansi-green-fg">is</span> <span class="ansi-green-fg">not</span> <span class="ansi-green-fg">None</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 345</span><span class="ansi-red-fg">             </span>self<span class="ansi-blue-fg">.</span>_initialize_model_properties<span class="ansi-blue-fg">(</span>args<span class="ansi-blue-fg">,</span> kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg ansi-bold">    346</span>         <span class="ansi-green-fg">if</span> self<span class="ansi-blue-fg">.</span>initial_params<span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg ansi-bold">    347</span>             z <span class="ansi-blue-fg">=</span> <span class="ansi-blue-fg">{</span>k<span class="ansi-blue-fg">:</span> v<span class="ansi-blue-fg">.</span>detach<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span> <span class="ansi-green-fg">for</span> k<span class="ansi-blue-fg">,</span> v <span class="ansi-green-fg">in</span> self<span class="ansi-blue-fg">.</span>initial_params<span class="ansi-blue-fg">.</span>items<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">}</span>

<span class="ansi-green-fg">/usr/local/lib/python3.12/dist-packages/pyro/infer/mcmc/hmc.py</span> in <span class="ansi-cyan-fg">_initialize_model_properties</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-fg ansi-bold">    277</span> 
<span class="ansi-green-fg ansi-bold">    278</span>     <span class="ansi-green-fg">def</span> _initialize_model_properties<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> model_args<span class="ansi-blue-fg">,</span> model_kwargs<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 279</span><span class="ansi-red-fg">         init_params, potential_fn, transforms, trace = initialize_model(
</span><span class="ansi-green-fg ansi-bold">    280</span>             self<span class="ansi-blue-fg">.</span>model<span class="ansi-blue-fg">,</span>
<span class="ansi-green-fg ansi-bold">    281</span>             model_args<span class="ansi-blue-fg">,</span>

<span class="ansi-green-fg">/usr/local/lib/python3.12/dist-packages/pyro/infer/mcmc/util.py</span> in <span class="ansi-cyan-fg">initialize_model</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-fg ansi-bold">    466</span>         <span class="ansi-red-fg"># enable potential_fn to be picklable (a torch._C.Function cannot be pickled).</span>
<span class="ansi-green-fg ansi-bold">    467</span>         <span class="ansi-red-fg"># We pass model_trace merely for computational savings.</span>
<span class="ansi-green-fg">--&gt; 468</span><span class="ansi-red-fg">         initial_params = _find_valid_initial_params(
</span><span class="ansi-green-fg ansi-bold">    469</span>             model<span class="ansi-blue-fg">,</span>
<span class="ansi-green-fg ansi-bold">    470</span>             model_args<span class="ansi-blue-fg">,</span>

<span class="ansi-green-fg">/usr/local/lib/python3.12/dist-packages/pyro/infer/mcmc/util.py</span> in <span class="ansi-cyan-fg">_find_valid_initial_params</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-fg ansi-bold">    349</span>         samples <span class="ansi-blue-fg">=</span> <span class="ansi-blue-fg">{</span>name<span class="ansi-blue-fg">:</span> trace<span class="ansi-blue-fg">.</span>nodes<span class="ansi-blue-fg">[</span>name<span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">[</span><span class="ansi-blue-fg">"value"</span><span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">.</span>detach<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span> <span class="ansi-green-fg">for</span> name <span class="ansi-green-fg">in</span> params<span class="ansi-blue-fg">}</span>
<span class="ansi-green-fg ansi-bold">    350</span>         params <span class="ansi-blue-fg">=</span> <span class="ansi-blue-fg">{</span>k<span class="ansi-blue-fg">:</span> transforms<span class="ansi-blue-fg">[</span>k<span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">(</span>v<span class="ansi-blue-fg">)</span> <span class="ansi-green-fg">for</span> k<span class="ansi-blue-fg">,</span> v <span class="ansi-green-fg">in</span> samples<span class="ansi-blue-fg">.</span>items<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">}</span>
<span class="ansi-green-fg">--&gt; 351</span><span class="ansi-red-fg">         </span>pe_grad<span class="ansi-blue-fg">,</span> pe <span class="ansi-blue-fg">=</span> potential_grad<span class="ansi-blue-fg">(</span>potential_fn<span class="ansi-blue-fg">,</span> params<span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg ansi-bold">    352</span> 
<span class="ansi-green-fg ansi-bold">    353</span>         if torch.isfinite(pe) and all(

<span class="ansi-green-fg">/usr/local/lib/python3.12/dist-packages/pyro/ops/integrator.py</span> in <span class="ansi-cyan-fg">potential_grad</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-fg ansi-bold">     89</span>         <span class="ansi-green-fg">else</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg ansi-bold">     90</span>             <span class="ansi-green-fg">raise</span> e
<span class="ansi-green-fg">---&gt; 91</span><span class="ansi-red-fg">     </span>grads <span class="ansi-blue-fg">=</span> grad<span class="ansi-blue-fg">(</span>potential_energy<span class="ansi-blue-fg">,</span> z_nodes<span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg ansi-bold">     92</span>     <span class="ansi-green-fg">for</span> node <span class="ansi-green-fg">in</span> z_nodes<span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg ansi-bold">     93</span>         node<span class="ansi-blue-fg">.</span>requires_grad_<span class="ansi-blue-fg">(</span><span class="ansi-green-fg">False</span><span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">/usr/local/lib/python3.12/dist-packages/torch/autograd/__init__.py</span> in <span class="ansi-cyan-fg">grad</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-fg ansi-bold">    450</span>     overridable_args <span class="ansi-blue-fg">=</span> t_outputs <span class="ansi-blue-fg">+</span> t_inputs
<span class="ansi-green-fg ansi-bold">    451</span>     <span class="ansi-green-fg">if</span> has_torch_function<span class="ansi-blue-fg">(</span>overridable_args<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 452</span><span class="ansi-red-fg">         return handle_torch_function(
</span><span class="ansi-green-fg ansi-bold">    453</span>             grad<span class="ansi-blue-fg">,</span>
<span class="ansi-green-fg ansi-bold">    454</span>             overridable_args<span class="ansi-blue-fg">,</span>

<span class="ansi-green-fg">/usr/local/lib/python3.12/dist-packages/torch/overrides.py</span> in <span class="ansi-cyan-fg">handle_torch_function</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-fg ansi-bold">   1726</span>         <span class="ansi-red-fg"># this unsets it and calls directly into TorchFunctionStackMode's torch function</span>
<span class="ansi-green-fg ansi-bold">   1727</span>         <span class="ansi-green-fg">with</span> _pop_mode_temporarily<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span> <span class="ansi-green-fg">as</span> mode<span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">-&gt; 1728</span><span class="ansi-red-fg">             </span>result <span class="ansi-blue-fg">=</span> mode<span class="ansi-blue-fg">.</span>__torch_function__<span class="ansi-blue-fg">(</span>public_api<span class="ansi-blue-fg">,</span> types<span class="ansi-blue-fg">,</span> args<span class="ansi-blue-fg">,</span> kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg ansi-bold">   1729</span>         <span class="ansi-green-fg">if</span> result <span class="ansi-green-fg">is</span> <span class="ansi-green-fg">not</span> NotImplemented<span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg ansi-bold">   1730</span>             <span class="ansi-green-fg">return</span> result

<span class="ansi-green-fg">/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py</span> in <span class="ansi-cyan-fg">__torch_function__</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-fg ansi-bold">    101</span>         <span class="ansi-green-fg">if</span> func <span class="ansi-green-fg">in</span> _device_constructors<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span> <span class="ansi-green-fg">and</span> kwargs<span class="ansi-blue-fg">.</span>get<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">"device"</span><span class="ansi-blue-fg">)</span> <span class="ansi-green-fg">is</span> <span class="ansi-green-fg">None</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg ansi-bold">    102</span>             kwargs<span class="ansi-blue-fg">[</span><span class="ansi-blue-fg">"device"</span><span class="ansi-blue-fg">]</span> <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>device
<span class="ansi-green-fg">--&gt; 103</span><span class="ansi-red-fg">         </span><span class="ansi-green-fg">return</span> func<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg ansi-bold">    104</span> 
<span class="ansi-green-fg ansi-bold">    105</span> 

<span class="ansi-green-fg">/usr/local/lib/python3.12/dist-packages/torch/autograd/__init__.py</span> in <span class="ansi-cyan-fg">grad</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-fg ansi-bold">    501</span>         )
<span class="ansi-green-fg ansi-bold">    502</span>     <span class="ansi-green-fg">else</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 503</span><span class="ansi-red-fg">         result = _engine_run_backward(
</span><span class="ansi-green-fg ansi-bold">    504</span>             outputs<span class="ansi-blue-fg">,</span>
<span class="ansi-green-fg ansi-bold">    505</span>             grad_outputs_<span class="ansi-blue-fg">,</span>

<span class="ansi-green-fg">/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py</span> in <span class="ansi-cyan-fg">_engine_run_backward</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-fg ansi-bold">    839</span>         unregister_hooks <span class="ansi-blue-fg">=</span> _register_logging_hooks_on_whole_graph<span class="ansi-blue-fg">(</span>t_outputs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg ansi-bold">    840</span>     <span class="ansi-green-fg">try</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 841</span><span class="ansi-red-fg">         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
</span><span class="ansi-green-fg ansi-bold">    842</span>             t_outputs<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs
<span class="ansi-green-fg ansi-bold">    843</span>         )  # Calls into the C++ engine to run the backward pass

<span class="ansi-red-fg">RuntimeError</span>: Unable to handle autograd's threading in combination with fork-based multiprocessing. See https://github.com/pytorch/pytorch/wiki/Autograd-and-Fork</pre>
</div>
</div>
</div>
<p><strong>Reasoning</strong>: The previous error indicates a conflict between PyTorch’s autograd and fork-based multiprocessing when running MCMC with multiple chains. To resolve this, I will set <code>num_chains=1</code> for the MCMC sampler, which forces inference to run in a single process and avoids the multiprocessing issue.</p>
<div id="cell-19" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="e481e09c-cb5e-4d13-9d70-d9400ff289e2" data-execution_count="34">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pyro</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pyro.distributions <span class="im">as</span> dist</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pyro.infer <span class="im">as</span> infer</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyro.infer.mcmc <span class="im">import</span> MCMC, NUTS</span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Set random seed for reproducibility</span></span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a>pyro.set_rng_seed(<span class="dv">1</span>)</span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert relevant columns to PyTorch tensors</span></span>
<span id="cb26-10"><a href="#cb26-10" aria-hidden="true" tabindex="-1"></a>clip_similarity_data <span class="op">=</span> torch.tensor(df_pyro[<span class="st">'CLIP_Similarity'</span>].values, dtype<span class="op">=</span>torch.float32)</span>
<span id="cb26-11"><a href="#cb26-11" aria-hidden="true" tabindex="-1"></a>verb_type_encoded <span class="op">=</span> torch.tensor(df_pyro[<span class="st">'VerbType'</span>].values, dtype<span class="op">=</span>torch.float32)</span>
<span id="cb26-12"><a href="#cb26-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-13"><a href="#cb26-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the linear regression model for CLIP_Similarity</span></span>
<span id="cb26-14"><a href="#cb26-14" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> model_clip_similarity(verb_type_encoded, obs_data<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb26-15"><a href="#cb26-15" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Priors for the intercept and the coefficient for VerbType</span></span>
<span id="cb26-16"><a href="#cb26-16" aria-hidden="true" tabindex="-1"></a>    alpha <span class="op">=</span> pyro.sample(<span class="st">'alpha'</span>, dist.Normal(<span class="fl">0.</span>, <span class="fl">10.</span>))</span>
<span id="cb26-17"><a href="#cb26-17" aria-hidden="true" tabindex="-1"></a>    beta <span class="op">=</span> pyro.sample(<span class="st">'beta'</span>, dist.Normal(<span class="fl">0.</span>, <span class="fl">10.</span>))</span>
<span id="cb26-18"><a href="#cb26-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-19"><a href="#cb26-19" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Linear predictor</span></span>
<span id="cb26-20"><a href="#cb26-20" aria-hidden="true" tabindex="-1"></a>    mu <span class="op">=</span> alpha <span class="op">+</span> beta <span class="op">*</span> verb_type_encoded</span>
<span id="cb26-21"><a href="#cb26-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-22"><a href="#cb26-22" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Observation likelihood</span></span>
<span id="cb26-23"><a href="#cb26-23" aria-hidden="true" tabindex="-1"></a>    sigma <span class="op">=</span> pyro.sample(<span class="st">'sigma'</span>, dist.HalfCauchy(<span class="fl">1.</span>))</span>
<span id="cb26-24"><a href="#cb26-24" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> pyro.plate(<span class="st">'data'</span>, <span class="bu">len</span>(verb_type_encoded)):</span>
<span id="cb26-25"><a href="#cb26-25" aria-hidden="true" tabindex="-1"></a>        pyro.sample(<span class="st">'obs'</span>, dist.Normal(mu, sigma), obs<span class="op">=</span>obs_data)</span>
<span id="cb26-26"><a href="#cb26-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-27"><a href="#cb26-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Set up NUTS sampler</span></span>
<span id="cb26-28"><a href="#cb26-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Changed num_chains to 1 to avoid multiprocessing issues with autograd in this environment</span></span>
<span id="cb26-29"><a href="#cb26-29" aria-hidden="true" tabindex="-1"></a>kernel <span class="op">=</span> NUTS(model_clip_similarity)</span>
<span id="cb26-30"><a href="#cb26-30" aria-hidden="true" tabindex="-1"></a>mcmc_clip <span class="op">=</span> MCMC(kernel, num_samples<span class="op">=</span><span class="dv">1000</span>, warmup_steps<span class="op">=</span><span class="dv">500</span>, num_chains<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb26-31"><a href="#cb26-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-32"><a href="#cb26-32" aria-hidden="true" tabindex="-1"></a><span class="co"># Run inference</span></span>
<span id="cb26-33"><a href="#cb26-33" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Running MCMC for CLIP Similarity model..."</span>)</span>
<span id="cb26-34"><a href="#cb26-34" aria-hidden="true" tabindex="-1"></a>mcmc_clip.run(verb_type_encoded, obs_data<span class="op">=</span>clip_similarity_data)</span>
<span id="cb26-35"><a href="#cb26-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-36"><a href="#cb26-36" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"MCMC for CLIP Similarity model complete."</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Running MCMC for CLIP Similarity model...</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Sample: 100%|██████████| 1500/1500 [00:20, 73.26it/s, step size=7.57e-01, acc. prob=0.882] </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>MCMC for CLIP Similarity model complete.</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code></code></pre>
</div>
</div>
<p><strong>Reasoning</strong>: Now that the MCMC sampling for the CLIP Similarity model is complete, I will analyze the results by extracting the posterior samples, visualizing their distributions, and calculating the probability of the ‘VerbType’ coefficient (‘beta’) being less than or greater than zero, as well as its 94% HPD interval.</p>
<div id="cell-21" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:662}}" data-outputid="3dd2c22f-a67b-40dd-cff2-9f4b10b17d4d" data-execution_count="35">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> arviz <span class="im">as</span> az</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Get posterior samples</span></span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a>posterior_samples_clip <span class="op">=</span> mcmc_clip.get_samples()</span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract alpha and beta samples</span></span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a>alpha_samples_clip <span class="op">=</span> posterior_samples_clip[<span class="st">'alpha'</span>].cpu().numpy()</span>
<span id="cb31-10"><a href="#cb31-10" aria-hidden="true" tabindex="-1"></a>beta_samples_clip <span class="op">=</span> posterior_samples_clip[<span class="st">'beta'</span>].cpu().numpy()</span>
<span id="cb31-11"><a href="#cb31-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-12"><a href="#cb31-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a dictionary for arviz.plot_posterior</span></span>
<span id="cb31-13"><a href="#cb31-13" aria-hidden="true" tabindex="-1"></a>data_clip <span class="op">=</span> {</span>
<span id="cb31-14"><a href="#cb31-14" aria-hidden="true" tabindex="-1"></a>    <span class="st">'alpha'</span>: alpha_samples_clip,</span>
<span id="cb31-15"><a href="#cb31-15" aria-hidden="true" tabindex="-1"></a>    <span class="st">'beta'</span>: beta_samples_clip</span>
<span id="cb31-16"><a href="#cb31-16" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb31-17"><a href="#cb31-17" aria-hidden="true" tabindex="-1"></a>idata_clip <span class="op">=</span> az.from_dict(posterior<span class="op">=</span>data_clip)</span>
<span id="cb31-18"><a href="#cb31-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-19"><a href="#cb31-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot posterior distributions</span></span>
<span id="cb31-20"><a href="#cb31-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Visualizing Posterior Distributions for CLIP Similarity Model..."</span>)</span>
<span id="cb31-21"><a href="#cb31-21" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">5</span>))</span>
<span id="cb31-22"><a href="#cb31-22" aria-hidden="true" tabindex="-1"></a>az.plot_posterior(idata_clip, var_names<span class="op">=</span>[<span class="st">'alpha'</span>], ax<span class="op">=</span>axes[<span class="dv">0</span>])</span>
<span id="cb31-23"><a href="#cb31-23" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_title(<span class="st">'Posterior of Intercept (alpha) for CLIP Similarity'</span>)</span>
<span id="cb31-24"><a href="#cb31-24" aria-hidden="true" tabindex="-1"></a>az.plot_posterior(idata_clip, var_names<span class="op">=</span>[<span class="st">'beta'</span>], ax<span class="op">=</span>axes[<span class="dv">1</span>])</span>
<span id="cb31-25"><a href="#cb31-25" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_title(<span class="st">'Posterior of VerbType Effect (beta) for CLIP Similarity'</span>)</span>
<span id="cb31-26"><a href="#cb31-26" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb31-27"><a href="#cb31-27" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb31-28"><a href="#cb31-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-29"><a href="#cb31-29" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate probabilities and HPD interval for beta</span></span>
<span id="cb31-30"><a href="#cb31-30" aria-hidden="true" tabindex="-1"></a>p_beta_lt_zero_clip <span class="op">=</span> (beta_samples_clip <span class="op">&lt;</span> <span class="dv">0</span>).mean()</span>
<span id="cb31-31"><a href="#cb31-31" aria-hidden="true" tabindex="-1"></a>p_beta_gt_zero_clip <span class="op">=</span> (beta_samples_clip <span class="op">&gt;</span> <span class="dv">0</span>).mean()</span>
<span id="cb31-32"><a href="#cb31-32" aria-hidden="true" tabindex="-1"></a>hpd_beta_clip <span class="op">=</span> az.hdi(beta_samples_clip, hdi_prob<span class="op">=</span><span class="fl">0.94</span>)</span>
<span id="cb31-33"><a href="#cb31-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-34"><a href="#cb31-34" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">CLIP Similarity Model Analysis:"</span>)</span>
<span id="cb31-35"><a href="#cb31-35" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Posterior Mean of alpha: </span><span class="sc">{</span>alpha_samples_clip<span class="sc">.</span>mean()<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb31-36"><a href="#cb31-36" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Posterior Mean of beta (VerbType effect): </span><span class="sc">{</span>beta_samples_clip<span class="sc">.</span>mean()<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb31-37"><a href="#cb31-37" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Probability (beta &lt; 0): </span><span class="sc">{</span>p_beta_lt_zero_clip<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb31-38"><a href="#cb31-38" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Probability (beta &gt; 0): </span><span class="sc">{</span>p_beta_gt_zero_clip<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb31-39"><a href="#cb31-39" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  94% HPD for beta: [</span><span class="sc">{</span>hpd_beta_clip[<span class="dv">0</span>]<span class="sc">:.3f}</span><span class="ss">, </span><span class="sc">{</span>hpd_beta_clip[<span class="dv">1</span>]<span class="sc">:.3f}</span><span class="ss">]"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Visualizing Posterior Distributions for CLIP Similarity Model...</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="clip_analysis_files/figure-html/cell-13-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
CLIP Similarity Model Analysis:
  Posterior Mean of alpha: 0.000
  Posterior Mean of beta (VerbType effect): -2.254
  Probability (beta &lt; 0): 0.936
  Probability (beta &gt; 0): 0.064
  94% HPD for beta: [-5.265, 0.348]</code></pre>
</div>
</div>
<p><strong>Reasoning</strong>: Now that the CLIP Similarity model has been analyzed, I will define and run a Bayesian linear regression model for ‘Subject_Salience’ using ‘VerbType’ as a predictor, similar to the previous step, to investigate its effect on subject salience.</p>
<div id="cell-23" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="4ccecafd-cf4d-48f0-c7c0-51d325ba4d5b" data-execution_count="36">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pyro</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pyro.distributions <span class="im">as</span> dist</span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pyro.infer <span class="im">as</span> infer</span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyro.infer.mcmc <span class="im">import</span> MCMC, NUTS</span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Set random seed for reproducibility</span></span>
<span id="cb34-7"><a href="#cb34-7" aria-hidden="true" tabindex="-1"></a>pyro.set_rng_seed(<span class="dv">1</span>)</span>
<span id="cb34-8"><a href="#cb34-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-9"><a href="#cb34-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert relevant columns to PyTorch tensors</span></span>
<span id="cb34-10"><a href="#cb34-10" aria-hidden="true" tabindex="-1"></a>subject_salience_data <span class="op">=</span> torch.tensor(df_pyro[<span class="st">'Subject_Salience'</span>].values, dtype<span class="op">=</span>torch.float32)</span>
<span id="cb34-11"><a href="#cb34-11" aria-hidden="true" tabindex="-1"></a>verb_type_encoded <span class="op">=</span> torch.tensor(df_pyro[<span class="st">'VerbType'</span>].values, dtype<span class="op">=</span>torch.float32)</span>
<span id="cb34-12"><a href="#cb34-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-13"><a href="#cb34-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the linear regression model for Subject_Salience</span></span>
<span id="cb34-14"><a href="#cb34-14" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> model_subject_salience(verb_type_encoded, obs_data<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb34-15"><a href="#cb34-15" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Priors for the intercept and the coefficient for VerbType</span></span>
<span id="cb34-16"><a href="#cb34-16" aria-hidden="true" tabindex="-1"></a>    alpha <span class="op">=</span> pyro.sample(<span class="st">'alpha'</span>, dist.Normal(<span class="fl">0.</span>, <span class="fl">10.</span>))</span>
<span id="cb34-17"><a href="#cb34-17" aria-hidden="true" tabindex="-1"></a>    beta <span class="op">=</span> pyro.sample(<span class="st">'beta'</span>, dist.Normal(<span class="fl">0.</span>, <span class="fl">10.</span>))</span>
<span id="cb34-18"><a href="#cb34-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-19"><a href="#cb34-19" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Linear predictor</span></span>
<span id="cb34-20"><a href="#cb34-20" aria-hidden="true" tabindex="-1"></a>    mu <span class="op">=</span> alpha <span class="op">+</span> beta <span class="op">*</span> verb_type_encoded</span>
<span id="cb34-21"><a href="#cb34-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-22"><a href="#cb34-22" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Observation likelihood</span></span>
<span id="cb34-23"><a href="#cb34-23" aria-hidden="true" tabindex="-1"></a>    sigma <span class="op">=</span> pyro.sample(<span class="st">'sigma'</span>, dist.HalfCauchy(<span class="fl">1.</span>))</span>
<span id="cb34-24"><a href="#cb34-24" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> pyro.plate(<span class="st">'data'</span>, <span class="bu">len</span>(verb_type_encoded)):</span>
<span id="cb34-25"><a href="#cb34-25" aria-hidden="true" tabindex="-1"></a>        pyro.sample(<span class="st">'obs'</span>, dist.Normal(mu, sigma), obs<span class="op">=</span>obs_data)</span>
<span id="cb34-26"><a href="#cb34-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-27"><a href="#cb34-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Set up NUTS sampler</span></span>
<span id="cb34-28"><a href="#cb34-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Changed num_chains to 1 to avoid multiprocessing issues with autograd in this environment</span></span>
<span id="cb34-29"><a href="#cb34-29" aria-hidden="true" tabindex="-1"></a>kernel <span class="op">=</span> NUTS(model_subject_salience)</span>
<span id="cb34-30"><a href="#cb34-30" aria-hidden="true" tabindex="-1"></a>mcmc_subj <span class="op">=</span> MCMC(kernel, num_samples<span class="op">=</span><span class="dv">1000</span>, warmup_steps<span class="op">=</span><span class="dv">500</span>, num_chains<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb34-31"><a href="#cb34-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-32"><a href="#cb34-32" aria-hidden="true" tabindex="-1"></a><span class="co"># Run inference</span></span>
<span id="cb34-33"><a href="#cb34-33" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Running MCMC for Subject Salience model..."</span>)</span>
<span id="cb34-34"><a href="#cb34-34" aria-hidden="true" tabindex="-1"></a>mcmc_subj.run(verb_type_encoded, obs_data<span class="op">=</span>subject_salience_data)</span>
<span id="cb34-35"><a href="#cb34-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-36"><a href="#cb34-36" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"MCMC for Subject Salience model complete."</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Running MCMC for Subject Salience model...</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Sample: 100%|██████████| 1500/1500 [00:20, 71.79it/s, step size=7.44e-01, acc. prob=0.914]</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>MCMC for Subject Salience model complete.</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code></code></pre>
</div>
</div>
<p><strong>Reasoning</strong>: Now that the MCMC sampling for the Subject Salience model is complete, I will analyze the results by extracting the posterior samples, visualizing their distributions, and calculating the probability of the ‘VerbType’ coefficient (‘beta’) being less than or greater than zero, as well as its 94% HPD interval, similar to the analysis performed for the CLIP Similarity model.</p>
<div id="cell-25" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:662}}" data-outputid="d8032318-d932-4f5b-97a3-2b079059ef56" data-execution_count="37">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> arviz <span class="im">as</span> az</span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Get posterior samples</span></span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a>posterior_samples_subj <span class="op">=</span> mcmc_subj.get_samples()</span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-8"><a href="#cb39-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract alpha and beta samples</span></span>
<span id="cb39-9"><a href="#cb39-9" aria-hidden="true" tabindex="-1"></a>alpha_samples_subj <span class="op">=</span> posterior_samples_subj[<span class="st">'alpha'</span>].cpu().numpy()</span>
<span id="cb39-10"><a href="#cb39-10" aria-hidden="true" tabindex="-1"></a>beta_samples_subj <span class="op">=</span> posterior_samples_subj[<span class="st">'beta'</span>].cpu().numpy()</span>
<span id="cb39-11"><a href="#cb39-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-12"><a href="#cb39-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a dictionary for arviz.plot_posterior</span></span>
<span id="cb39-13"><a href="#cb39-13" aria-hidden="true" tabindex="-1"></a>data_subj <span class="op">=</span> {</span>
<span id="cb39-14"><a href="#cb39-14" aria-hidden="true" tabindex="-1"></a>    <span class="st">'alpha'</span>: alpha_samples_subj,</span>
<span id="cb39-15"><a href="#cb39-15" aria-hidden="true" tabindex="-1"></a>    <span class="st">'beta'</span>: beta_samples_subj</span>
<span id="cb39-16"><a href="#cb39-16" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb39-17"><a href="#cb39-17" aria-hidden="true" tabindex="-1"></a>idata_subj <span class="op">=</span> az.from_dict(posterior<span class="op">=</span>data_subj)</span>
<span id="cb39-18"><a href="#cb39-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-19"><a href="#cb39-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot posterior distributions</span></span>
<span id="cb39-20"><a href="#cb39-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Visualizing Posterior Distributions for Subject Salience Model..."</span>)</span>
<span id="cb39-21"><a href="#cb39-21" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">5</span>))</span>
<span id="cb39-22"><a href="#cb39-22" aria-hidden="true" tabindex="-1"></a>az.plot_posterior(idata_subj, var_names<span class="op">=</span>[<span class="st">'alpha'</span>], ax<span class="op">=</span>axes[<span class="dv">0</span>])</span>
<span id="cb39-23"><a href="#cb39-23" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_title(<span class="st">'Posterior of Intercept (alpha) for Subject Salience'</span>)</span>
<span id="cb39-24"><a href="#cb39-24" aria-hidden="true" tabindex="-1"></a>az.plot_posterior(idata_subj, var_names<span class="op">=</span>[<span class="st">'beta'</span>], ax<span class="op">=</span>axes[<span class="dv">1</span>])</span>
<span id="cb39-25"><a href="#cb39-25" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_title(<span class="st">'Posterior of VerbType Effect (beta) for Subject Salience'</span>)</span>
<span id="cb39-26"><a href="#cb39-26" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb39-27"><a href="#cb39-27" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb39-28"><a href="#cb39-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-29"><a href="#cb39-29" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate probabilities and HPD interval for beta</span></span>
<span id="cb39-30"><a href="#cb39-30" aria-hidden="true" tabindex="-1"></a>p_beta_lt_zero_subj <span class="op">=</span> (beta_samples_subj <span class="op">&lt;</span> <span class="dv">0</span>).mean()</span>
<span id="cb39-31"><a href="#cb39-31" aria-hidden="true" tabindex="-1"></a>p_beta_gt_zero_subj <span class="op">=</span> (beta_samples_subj <span class="op">&gt;</span> <span class="dv">0</span>).mean()</span>
<span id="cb39-32"><a href="#cb39-32" aria-hidden="true" tabindex="-1"></a>hpd_beta_subj <span class="op">=</span> az.hdi(beta_samples_subj, hdi_prob<span class="op">=</span><span class="fl">0.94</span>)</span>
<span id="cb39-33"><a href="#cb39-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-34"><a href="#cb39-34" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Subject Salience Model Analysis:"</span>)</span>
<span id="cb39-35"><a href="#cb39-35" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Posterior Mean of alpha: </span><span class="sc">{</span>alpha_samples_subj<span class="sc">.</span>mean()<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb39-36"><a href="#cb39-36" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Posterior Mean of beta (VerbType effect): </span><span class="sc">{</span>beta_samples_subj<span class="sc">.</span>mean()<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb39-37"><a href="#cb39-37" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Probability (beta &lt; 0): </span><span class="sc">{</span>p_beta_lt_zero_subj<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb39-38"><a href="#cb39-38" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Probability (beta &gt; 0): </span><span class="sc">{</span>p_beta_gt_zero_subj<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb39-39"><a href="#cb39-39" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  94% HPD for beta: [</span><span class="sc">{</span>hpd_beta_subj[<span class="dv">0</span>]<span class="sc">:.3f}</span><span class="ss">, </span><span class="sc">{</span>hpd_beta_subj[<span class="dv">1</span>]<span class="sc">:.3f}</span><span class="ss">]"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Visualizing Posterior Distributions for Subject Salience Model...</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="clip_analysis_files/figure-html/cell-15-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
Subject Salience Model Analysis:
  Posterior Mean of alpha: 0.026
  Posterior Mean of beta (VerbType effect): -1.502
  Probability (beta &lt; 0): 0.818
  Probability (beta &gt; 0): 0.182
  94% HPD for beta: [-4.741, 1.698]</code></pre>
</div>
</div>
<p><strong>Reasoning</strong>: Now that the Subject Salience model has been analyzed, I will define and run an ordered logistic regression model for ‘VLM_Score’ using ‘VerbType’ as a predictor. This requires preparing the ‘VLM_Score’ data and defining a Pyro model with appropriate priors for the intercept, the ‘VerbType’ coefficient, and cutpoints for the ordered categories.</p>
<div id="cell-27" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="7e81dd50-f0ad-4a4e-96fe-47fd85424ca8" data-execution_count="39">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb42"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pyro</span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pyro.distributions <span class="im">as</span> dist</span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pyro.infer <span class="im">as</span> infer</span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyro.infer.mcmc <span class="im">import</span> MCMC, NUTS</span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-6"><a href="#cb42-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Set random seed for reproducibility</span></span>
<span id="cb42-7"><a href="#cb42-7" aria-hidden="true" tabindex="-1"></a>pyro.set_rng_seed(<span class="dv">1</span>)</span>
<span id="cb42-8"><a href="#cb42-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-9"><a href="#cb42-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert relevant columns to PyTorch tensors</span></span>
<span id="cb42-10"><a href="#cb42-10" aria-hidden="true" tabindex="-1"></a>vlm_score_data <span class="op">=</span> torch.tensor(df_pyro[<span class="st">'VLM_Score'</span>].values, dtype<span class="op">=</span>torch.<span class="bu">long</span>) <span class="co"># VLM_Score is integer</span></span>
<span id="cb42-11"><a href="#cb42-11" aria-hidden="true" tabindex="-1"></a><span class="co"># verb_type_encoded is already defined from previous steps</span></span>
<span id="cb42-12"><a href="#cb42-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-13"><a href="#cb42-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Determine number of categories and cutpoints for ordered logistic regression</span></span>
<span id="cb42-14"><a href="#cb42-14" aria-hidden="true" tabindex="-1"></a>k_categories <span class="op">=</span> vlm_score_data.<span class="bu">max</span>().item() <span class="op">+</span> <span class="dv">1</span> <span class="co"># Assuming scores are 0-indexed, if 1-indexed, use max().item()</span></span>
<span id="cb42-15"><a href="#cb42-15" aria-hidden="true" tabindex="-1"></a>k_cutpoints <span class="op">=</span> k_categories <span class="op">-</span> <span class="dv">1</span></span>
<span id="cb42-16"><a href="#cb42-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-17"><a href="#cb42-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the ordered logistic regression model for VLM_Score</span></span>
<span id="cb42-18"><a href="#cb42-18" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> model_vlm_score(verb_type_encoded, obs_data<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb42-19"><a href="#cb42-19" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Priors for the intercept (latent mean when verb_type = 0) and the coefficient for VerbType</span></span>
<span id="cb42-20"><a href="#cb42-20" aria-hidden="true" tabindex="-1"></a>    alpha <span class="op">=</span> pyro.sample(<span class="st">'alpha'</span>, dist.Normal(<span class="fl">0.</span>, <span class="fl">10.</span>)) <span class="co"># Latent intercept</span></span>
<span id="cb42-21"><a href="#cb42-21" aria-hidden="true" tabindex="-1"></a>    beta <span class="op">=</span> pyro.sample(<span class="st">'beta'</span>, dist.Normal(<span class="fl">0.</span>, <span class="fl">10.</span>))   <span class="co"># Effect of VerbType on latent propensity</span></span>
<span id="cb42-22"><a href="#cb42-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-23"><a href="#cb42-23" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Ordered cutpoints. Ensure they are monotonically increasing.</span></span>
<span id="cb42-24"><a href="#cb42-24" aria-hidden="true" tabindex="-1"></a>    <span class="co"># We use a Normal prior for each, and then sort them for strict ordering.</span></span>
<span id="cb42-25"><a href="#cb42-25" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> pyro.plate(<span class="st">"cutpoints_plate"</span>, k_cutpoints):</span>
<span id="cb42-26"><a href="#cb42-26" aria-hidden="true" tabindex="-1"></a>        raw_cutpoints <span class="op">=</span> pyro.sample(<span class="st">'raw_cutpoints'</span>, dist.Normal(torch.arange(k_cutpoints).<span class="bu">float</span>(), <span class="fl">1.</span>))</span>
<span id="cb42-27"><a href="#cb42-27" aria-hidden="true" tabindex="-1"></a>    cutpoints <span class="op">=</span> torch.sort(raw_cutpoints)[<span class="dv">0</span>]</span>
<span id="cb42-28"><a href="#cb42-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-29"><a href="#cb42-29" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Linear predictor for the latent propensity</span></span>
<span id="cb42-30"><a href="#cb42-30" aria-hidden="true" tabindex="-1"></a>    latent_propensity <span class="op">=</span> alpha <span class="op">+</span> beta <span class="op">*</span> verb_type_encoded</span>
<span id="cb42-31"><a href="#cb42-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-32"><a href="#cb42-32" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Observation likelihood (OrderedLogistic)</span></span>
<span id="cb42-33"><a href="#cb42-33" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> pyro.plate(<span class="st">'data'</span>, <span class="bu">len</span>(verb_type_encoded)):</span>
<span id="cb42-34"><a href="#cb42-34" aria-hidden="true" tabindex="-1"></a>        pyro.sample(<span class="st">'obs'</span>, dist.OrderedLogistic(latent_propensity, cutpoints), obs<span class="op">=</span>obs_data)</span>
<span id="cb42-35"><a href="#cb42-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-36"><a href="#cb42-36" aria-hidden="true" tabindex="-1"></a><span class="co"># Set up NUTS sampler</span></span>
<span id="cb42-37"><a href="#cb42-37" aria-hidden="true" tabindex="-1"></a><span class="co"># Changed num_chains to 1 to avoid multiprocessing issues with autograd in this environment</span></span>
<span id="cb42-38"><a href="#cb42-38" aria-hidden="true" tabindex="-1"></a>kernel <span class="op">=</span> NUTS(model_vlm_score)</span>
<span id="cb42-39"><a href="#cb42-39" aria-hidden="true" tabindex="-1"></a>mcmc_vlm <span class="op">=</span> MCMC(kernel, num_samples<span class="op">=</span><span class="dv">1000</span>, warmup_steps<span class="op">=</span><span class="dv">500</span>, num_chains<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb42-40"><a href="#cb42-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-41"><a href="#cb42-41" aria-hidden="true" tabindex="-1"></a><span class="co"># Run inference</span></span>
<span id="cb42-42"><a href="#cb42-42" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Running MCMC for VLM Score model..."</span>)</span>
<span id="cb42-43"><a href="#cb42-43" aria-hidden="true" tabindex="-1"></a>mcmc_vlm.run(verb_type_encoded, obs_data<span class="op">=</span>vlm_score_data)</span>
<span id="cb42-44"><a href="#cb42-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-45"><a href="#cb42-45" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"MCMC for VLM Score model complete."</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Running MCMC for VLM Score model...</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Sample: 100%|██████████| 1500/1500 [02:03, 12.18it/s, step size=1.32e-01, acc. prob=0.827]</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>MCMC for VLM Score model complete.</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code></code></pre>
</div>
</div>
<p><strong>Reasoning</strong>: The previous code failed due to an unterminated string literal in the print statement. I will fix this by correctly closing the string literal and running the code again.</p>
<div id="cell-29" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="660c7c96-bd7b-4dbd-fc1b-4f29ae773cbc" data-execution_count="40">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb47"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pyro</span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pyro.distributions <span class="im">as</span> dist</span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pyro.infer <span class="im">as</span> infer</span>
<span id="cb47-4"><a href="#cb47-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyro.infer.mcmc <span class="im">import</span> MCMC, NUTS</span>
<span id="cb47-5"><a href="#cb47-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-6"><a href="#cb47-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Set random seed for reproducibility</span></span>
<span id="cb47-7"><a href="#cb47-7" aria-hidden="true" tabindex="-1"></a>pyro.set_rng_seed(<span class="dv">1</span>)</span>
<span id="cb47-8"><a href="#cb47-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-9"><a href="#cb47-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert relevant columns to PyTorch tensors</span></span>
<span id="cb47-10"><a href="#cb47-10" aria-hidden="true" tabindex="-1"></a>vlm_score_data <span class="op">=</span> torch.tensor(df_pyro[<span class="st">'VLM_Score'</span>].values, dtype<span class="op">=</span>torch.<span class="bu">long</span>) <span class="co"># VLM_Score is integer</span></span>
<span id="cb47-11"><a href="#cb47-11" aria-hidden="true" tabindex="-1"></a><span class="co"># verb_type_encoded is already defined from previous steps</span></span>
<span id="cb47-12"><a href="#cb47-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-13"><a href="#cb47-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Determine number of categories and cutpoints for ordered logistic regression</span></span>
<span id="cb47-14"><a href="#cb47-14" aria-hidden="true" tabindex="-1"></a>k_categories <span class="op">=</span> vlm_score_data.<span class="bu">max</span>().item() <span class="op">+</span> <span class="dv">1</span> <span class="co"># Assuming scores are 0-indexed, if 1-indexed, use max().item()</span></span>
<span id="cb47-15"><a href="#cb47-15" aria-hidden="true" tabindex="-1"></a>k_cutpoints <span class="op">=</span> k_categories <span class="op">-</span> <span class="dv">1</span></span>
<span id="cb47-16"><a href="#cb47-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-17"><a href="#cb47-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the ordered logistic regression model for VLM_Score</span></span>
<span id="cb47-18"><a href="#cb47-18" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> model_vlm_score(verb_type_encoded, obs_data<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb47-19"><a href="#cb47-19" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Priors for the intercept (latent mean when verb_type = 0) and the coefficient for VerbType</span></span>
<span id="cb47-20"><a href="#cb47-20" aria-hidden="true" tabindex="-1"></a>    alpha <span class="op">=</span> pyro.sample(<span class="st">'alpha'</span>, dist.Normal(<span class="fl">0.</span>, <span class="fl">10.</span>)) <span class="co"># Latent intercept</span></span>
<span id="cb47-21"><a href="#cb47-21" aria-hidden="true" tabindex="-1"></a>    beta <span class="op">=</span> pyro.sample(<span class="st">'beta'</span>, dist.Normal(<span class="fl">0.</span>, <span class="fl">10.</span>))   <span class="co"># Effect of VerbType on latent propensity</span></span>
<span id="cb47-22"><a href="#cb47-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-23"><a href="#cb47-23" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Ordered cutpoints. Ensure they are monotonically increasing.</span></span>
<span id="cb47-24"><a href="#cb47-24" aria-hidden="true" tabindex="-1"></a>    <span class="co"># We use a Normal prior for each, and then sort them for strict ordering.</span></span>
<span id="cb47-25"><a href="#cb47-25" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> pyro.plate(<span class="st">"cutpoints_plate"</span>, k_cutpoints):</span>
<span id="cb47-26"><a href="#cb47-26" aria-hidden="true" tabindex="-1"></a>        raw_cutpoints <span class="op">=</span> pyro.sample(<span class="st">'raw_cutpoints'</span>, dist.Normal(torch.arange(k_cutpoints).<span class="bu">float</span>(), <span class="fl">1.</span>))</span>
<span id="cb47-27"><a href="#cb47-27" aria-hidden="true" tabindex="-1"></a>    cutpoints <span class="op">=</span> torch.sort(raw_cutpoints)[<span class="dv">0</span>]</span>
<span id="cb47-28"><a href="#cb47-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-29"><a href="#cb47-29" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Linear predictor for the latent propensity</span></span>
<span id="cb47-30"><a href="#cb47-30" aria-hidden="true" tabindex="-1"></a>    latent_propensity <span class="op">=</span> alpha <span class="op">+</span> beta <span class="op">*</span> verb_type_encoded</span>
<span id="cb47-31"><a href="#cb47-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-32"><a href="#cb47-32" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Observation likelihood (OrderedLogistic)</span></span>
<span id="cb47-33"><a href="#cb47-33" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> pyro.plate(<span class="st">'data'</span>, <span class="bu">len</span>(verb_type_encoded)):</span>
<span id="cb47-34"><a href="#cb47-34" aria-hidden="true" tabindex="-1"></a>        pyro.sample(<span class="st">'obs'</span>, dist.OrderedLogistic(latent_propensity, cutpoints), obs<span class="op">=</span>obs_data)</span>
<span id="cb47-35"><a href="#cb47-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-36"><a href="#cb47-36" aria-hidden="true" tabindex="-1"></a><span class="co"># Set up NUTS sampler</span></span>
<span id="cb47-37"><a href="#cb47-37" aria-hidden="true" tabindex="-1"></a><span class="co"># Changed num_chains to 1 to avoid multiprocessing issues with autograd in this environment</span></span>
<span id="cb47-38"><a href="#cb47-38" aria-hidden="true" tabindex="-1"></a>kernel <span class="op">=</span> NUTS(model_vlm_score)</span>
<span id="cb47-39"><a href="#cb47-39" aria-hidden="true" tabindex="-1"></a>mcmc_vlm <span class="op">=</span> MCMC(kernel, num_samples<span class="op">=</span><span class="dv">1000</span>, warmup_steps<span class="op">=</span><span class="dv">500</span>, num_chains<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb47-40"><a href="#cb47-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-41"><a href="#cb47-41" aria-hidden="true" tabindex="-1"></a><span class="co"># Run inference</span></span>
<span id="cb47-42"><a href="#cb47-42" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Running MCMC for VLM Score model..."</span>)</span>
<span id="cb47-43"><a href="#cb47-43" aria-hidden="true" tabindex="-1"></a>mcmc_vlm.run(verb_type_encoded, obs_data<span class="op">=</span>vlm_score_data)</span>
<span id="cb47-44"><a href="#cb47-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-45"><a href="#cb47-45" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"MCMC for VLM Score model complete."</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Running MCMC for VLM Score model...</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Sample: 100%|██████████| 1500/1500 [02:03, 12.14it/s, step size=1.32e-01, acc. prob=0.827]</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>MCMC for VLM Score model complete.</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code></code></pre>
</div>
</div>
<p><strong>Reasoning</strong>: Now that the MCMC sampling for the VLM Score model is complete, I will analyze the results by extracting the posterior samples, visualizing their distributions, and calculating the probability of the ‘VerbType’ coefficient (‘beta’) being less than or greater than zero, as well as its 94% HPD interval, similar to the analysis performed for the previous models.</p>
<div id="cell-31" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:662}}" data-outputid="bc3e18c7-f1ea-43d1-d93f-f186d18fadb3" data-execution_count="41">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb52"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb52-3"><a href="#cb52-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> arviz <span class="im">as</span> az</span>
<span id="cb52-4"><a href="#cb52-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-5"><a href="#cb52-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Get posterior samples</span></span>
<span id="cb52-6"><a href="#cb52-6" aria-hidden="true" tabindex="-1"></a>posterior_samples_vlm <span class="op">=</span> mcmc_vlm.get_samples()</span>
<span id="cb52-7"><a href="#cb52-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-8"><a href="#cb52-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract alpha and beta samples</span></span>
<span id="cb52-9"><a href="#cb52-9" aria-hidden="true" tabindex="-1"></a>alpha_samples_vlm <span class="op">=</span> posterior_samples_vlm[<span class="st">'alpha'</span>].cpu().numpy()</span>
<span id="cb52-10"><a href="#cb52-10" aria-hidden="true" tabindex="-1"></a>beta_samples_vlm <span class="op">=</span> posterior_samples_vlm[<span class="st">'beta'</span>].cpu().numpy()</span>
<span id="cb52-11"><a href="#cb52-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-12"><a href="#cb52-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a dictionary for arviz.plot_posterior</span></span>
<span id="cb52-13"><a href="#cb52-13" aria-hidden="true" tabindex="-1"></a>data_vlm <span class="op">=</span> {</span>
<span id="cb52-14"><a href="#cb52-14" aria-hidden="true" tabindex="-1"></a>    <span class="st">'alpha'</span>: alpha_samples_vlm,</span>
<span id="cb52-15"><a href="#cb52-15" aria-hidden="true" tabindex="-1"></a>    <span class="st">'beta'</span>: beta_samples_vlm</span>
<span id="cb52-16"><a href="#cb52-16" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb52-17"><a href="#cb52-17" aria-hidden="true" tabindex="-1"></a>idata_vlm <span class="op">=</span> az.from_dict(posterior<span class="op">=</span>data_vlm)</span>
<span id="cb52-18"><a href="#cb52-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-19"><a href="#cb52-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot posterior distributions</span></span>
<span id="cb52-20"><a href="#cb52-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Visualizing Posterior Distributions for VLM Score Model..."</span>)</span>
<span id="cb52-21"><a href="#cb52-21" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">5</span>))</span>
<span id="cb52-22"><a href="#cb52-22" aria-hidden="true" tabindex="-1"></a>az.plot_posterior(idata_vlm, var_names<span class="op">=</span>[<span class="st">'alpha'</span>], ax<span class="op">=</span>axes[<span class="dv">0</span>])</span>
<span id="cb52-23"><a href="#cb52-23" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_title(<span class="st">'Posterior of Intercept (alpha) for VLM Score'</span>)</span>
<span id="cb52-24"><a href="#cb52-24" aria-hidden="true" tabindex="-1"></a>az.plot_posterior(idata_vlm, var_names<span class="op">=</span>[<span class="st">'beta'</span>], ax<span class="op">=</span>axes[<span class="dv">1</span>])</span>
<span id="cb52-25"><a href="#cb52-25" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_title(<span class="st">'Posterior of VerbType Effect (beta) for VLM Score'</span>)</span>
<span id="cb52-26"><a href="#cb52-26" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb52-27"><a href="#cb52-27" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb52-28"><a href="#cb52-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-29"><a href="#cb52-29" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate probabilities and HPD interval for beta</span></span>
<span id="cb52-30"><a href="#cb52-30" aria-hidden="true" tabindex="-1"></a>p_beta_lt_zero_vlm <span class="op">=</span> (beta_samples_vlm <span class="op">&lt;</span> <span class="dv">0</span>).mean()</span>
<span id="cb52-31"><a href="#cb52-31" aria-hidden="true" tabindex="-1"></a>p_beta_gt_zero_vlm <span class="op">=</span> (beta_samples_vlm <span class="op">&gt;</span> <span class="dv">0</span>).mean()</span>
<span id="cb52-32"><a href="#cb52-32" aria-hidden="true" tabindex="-1"></a>hpd_beta_vlm <span class="op">=</span> az.hdi(beta_samples_vlm, hdi_prob<span class="op">=</span><span class="fl">0.94</span>)</span>
<span id="cb52-33"><a href="#cb52-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-34"><a href="#cb52-34" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">VLM Score Model Analysis:"</span>)</span>
<span id="cb52-35"><a href="#cb52-35" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Posterior Mean of alpha: </span><span class="sc">{</span>alpha_samples_vlm<span class="sc">.</span>mean()<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb52-36"><a href="#cb52-36" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Posterior Mean of beta (VerbType effect): </span><span class="sc">{</span>beta_samples_vlm<span class="sc">.</span>mean()<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb52-37"><a href="#cb52-37" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Probability (beta &lt; 0): </span><span class="sc">{</span>p_beta_lt_zero_vlm<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb52-38"><a href="#cb52-38" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Probability (beta &gt; 0): </span><span class="sc">{</span>p_beta_gt_zero_vlm<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb52-39"><a href="#cb52-39" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  94% HPD for beta: [</span><span class="sc">{</span>hpd_beta_vlm[<span class="dv">0</span>]<span class="sc">:.3f}</span><span class="ss">, </span><span class="sc">{</span>hpd_beta_vlm[<span class="dv">1</span>]<span class="sc">:.3f}</span><span class="ss">]"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Visualizing Posterior Distributions for VLM Score Model...</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="clip_analysis_files/figure-html/cell-18-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
VLM Score Model Analysis:
  Posterior Mean of alpha: 4.860
  Posterior Mean of beta (VerbType effect): -1.822
  Probability (beta &lt; 0): 0.987
  Probability (beta &gt; 0): 0.013
  94% HPD for beta: [-3.366, -0.198]</code></pre>
</div>
</div>
</section>
<section id="summary-of-bayesian-analysis-with-pyro" class="level3">
<h3 class="anchored" data-anchor-id="summary-of-bayesian-analysis-with-pyro">Summary of Bayesian Analysis with Pyro:</h3>
<p>This analysis investigated the effect of ‘VerbType’ (Unergative: -0.5, Unaccusative: 0.5) on three different outcome variables: ‘CLIP_Similarity’, ‘Subject_Salience’, and ‘VLM_Score’, using Bayesian modeling with Pyro.</p>
<section id="clip-similarity-model-linear-regression" class="level4">
<h4 class="anchored" data-anchor-id="clip-similarity-model-linear-regression">1. CLIP Similarity Model (Linear Regression):</h4>
<ul>
<li><strong>Posterior Mean of Intercept (alpha)</strong>: 0.000 (indicating that when <code>VerbType</code> is centered, the average <code>CLIP_Similarity</code> is near zero).</li>
<li><strong>Posterior Mean of VerbType Effect (beta)</strong>: -2.254
<ul>
<li>This negative mean suggests that Unaccusative scenes (encoded as 0.5) are associated with a lower CLIP Similarity compared to Unergative scenes (encoded as -0.5).</li>
</ul></li>
<li><strong>Probability (beta &lt; 0)</strong>: 0.936
<ul>
<li>There is a 93.6% probability that the effect of ‘VerbType’ on ‘CLIP_Similarity’ is negative, meaning unaccusative scenes tend to have lower CLIP similarity scores.</li>
</ul></li>
<li><strong>Probability (beta &gt; 0)</strong>: 0.064</li>
<li><strong>94% HPD for beta</strong>: [-5.265, 0.348]
<ul>
<li>The 94% Highest Posterior Density interval for beta includes zero, suggesting that while there’s a strong tendency for a negative effect, it’s not statistically significant at this credible interval level.</li>
</ul></li>
</ul>
</section>
<section id="subject-salience-model-linear-regression" class="level4">
<h4 class="anchored" data-anchor-id="subject-salience-model-linear-regression">2. Subject Salience Model (Linear Regression):</h4>
<ul>
<li><strong>Posterior Mean of Intercept (alpha)</strong>: 0.026</li>
<li><strong>Posterior Mean of VerbType Effect (beta)</strong>: -1.502
<ul>
<li>This indicates that Unaccusative scenes tend to have lower Subject Salience scores compared to Unergative scenes.</li>
</ul></li>
<li><strong>Probability (beta &lt; 0)</strong>: 0.818
<ul>
<li>There is an 81.8% probability that the effect of ‘VerbType’ on ‘Subject_Salience’ is negative.</li>
</ul></li>
<li><strong>Probability (beta &gt; 0)</strong>: 0.182</li>
<li><strong>94% HPD for beta</strong>: [-4.741, 1.698]
<ul>
<li>The 94% HPD interval for beta includes zero, indicating that the observed negative effect is not statistically significant.</li>
</ul></li>
</ul>
</section>
<section id="vlm-score-model-ordered-logistic-regression" class="level4">
<h4 class="anchored" data-anchor-id="vlm-score-model-ordered-logistic-regression">3. VLM Score Model (Ordered Logistic Regression):</h4>
<ul>
<li><strong>Posterior Mean of Intercept (alpha)</strong>: 4.860 (representing the latent propensity when <code>VerbType</code> is centered).</li>
<li><strong>Posterior Mean of VerbType Effect (beta)</strong>: -1.822
<ul>
<li>This negative mean implies that Unaccusative scenes are associated with a lower latent propensity for higher VLM scores compared to Unergative scenes.</li>
</ul></li>
<li><strong>Probability (beta &lt; 0)</strong>: 0.987
<ul>
<li>There is a high probability (98.7%) that the effect of ‘VerbType’ on the latent propensity for ‘VLM_Score’ is negative, strongly suggesting that unaccusative scenes are rated lower by the VLM.</li>
</ul></li>
<li><strong>Probability (beta &gt; 0)</strong>: 0.013</li>
<li><strong>94% HPD for beta</strong>: [-3.366, -0.198]
<ul>
<li>The 94% HPD interval for beta <strong>does not include zero</strong>, which indicates that the negative effect of ‘VerbType’ on ‘VLM_Score’ is statistically significant. Unaccusative scenes are significantly associated with lower VLM ratings.</li>
</ul></li>
</ul>
</section>
</section>
<section id="overall-conclusion" class="level3">
<h3 class="anchored" data-anchor-id="overall-conclusion">Overall Conclusion:</h3>
<p>Across all three models, there is a consistent directional trend: <strong>Unaccusative scenes tend to be associated with lower scores</strong> in CLIP Similarity, Subject Salience, and VLM Score. While this trend is not statistically significant for CLIP Similarity and Subject Salience at the 94% HPD level (their credible intervals for <code>beta</code> include zero), the <strong>VLM Score model shows a statistically significant negative effect of Unaccusative verb types</strong>, with the 94% HPD interval entirely below zero. This suggests that the Qwen-VL-Chat model finds unaccusative scenes perceptually harder to interpret or verify against their descriptions than unergative scenes, aligning with the initial hypothesis that unaccusative scenes might be perceptually more challenging.</p>
</section>
</section>
<section id="summary-1" class="level2">
<h2 class="anchored" data-anchor-id="summary-1">Summary:</h2>
<section id="data-analysis-key-findings-1" class="level3">
<h3 class="anchored" data-anchor-id="data-analysis-key-findings-1">Data Analysis Key Findings</h3>
<p>The Bayesian analysis using Pyro revealed the following impacts of ‘VerbType’ (encoded as Unaccusative: <span class="math inline">\(0.5\)</span>, Unergative: <span class="math inline">\(-0.5\)</span>) on the three outcome variables:</p>
<ul>
<li><strong>CLIP Similarity:</strong>
<ul>
<li>The posterior mean of the ‘VerbType’ coefficient (<span class="math inline">\(\beta\)</span>) was <span class="math inline">\(-2.254\)</span>, indicating that Unaccusative scenes tend to be associated with lower CLIP Similarity scores compared to Unergative scenes.</li>
<li>There is a <span class="math inline">\(93.6\%\)</span> probability that the effect of ‘VerbType’ on ‘CLIP_Similarity’ is negative.</li>
<li>The <span class="math inline">\(94\%\)</span> Highest Posterior Density (HPD) interval for <span class="math inline">\(\beta\)</span> was <span class="math inline">\([-5.265, 0.348]\)</span>, which includes zero, suggesting this negative effect is not statistically significant at this credible interval level.</li>
</ul></li>
<li><strong>Subject Salience:</strong>
<ul>
<li>The posterior mean of the ‘VerbType’ coefficient (<span class="math inline">\(\beta\)</span>) was <span class="math inline">\(-1.502\)</span>, suggesting that Unaccusative scenes tend to have lower Subject Salience scores than Unergative scenes.</li>
<li>There is an <span class="math inline">\(81.8\%\)</span> probability that the effect of ‘VerbType’ on ‘Subject_Salience’ is negative.</li>
<li>The <span class="math inline">\(94\%\)</span> HPD interval for <span class="math inline">\(\beta\)</span> was <span class="math inline">\([-4.741, 1.698]\)</span>, which includes zero, indicating this negative effect is not statistically significant.</li>
</ul></li>
<li><strong>VLM Score:</strong>
<ul>
<li>The posterior mean of the ‘VerbType’ coefficient (<span class="math inline">\(\beta\)</span>) was <span class="math inline">\(-1.822\)</span>, implying that Unaccusative scenes are associated with a lower latent propensity for higher VLM scores compared to Unergative scenes.</li>
<li>There is a high probability (<span class="math inline">\(98.7\%\)</span>) that the effect of ‘VerbType’ on the latent propensity for ‘VLM_Score’ is negative.</li>
<li>The <span class="math inline">\(94\%\)</span> HPD interval for <span class="math inline">\(\beta\)</span> was <span class="math inline">\([-3.366, -0.198]\)</span>, which <strong>does not include zero</strong>. This indicates a statistically significant negative effect, suggesting that Unaccusative scenes are significantly associated with lower VLM ratings.</li>
</ul></li>
</ul>
</section>
<section id="insights-or-next-steps-1" class="level3">
<h3 class="anchored" data-anchor-id="insights-or-next-steps-1">Insights or Next Steps</h3>
<ul>
<li>Unaccusative verb types consistently show a negative association with CLIP Similarity, Subject Salience, and VLM Scores, aligning with the hypothesis that unaccusative scenes might be perceptually more challenging.</li>
<li>The statistically significant negative effect on VLM Scores suggests that the Qwen-VL-Chat model finds unaccusative scenes notably harder to interpret or verify against their descriptions compared to unergative scenes. Further investigation could explore specific features within unaccusative scenes that lead to these lower VLM ratings.</li>
</ul>


</section>
</section>
</section>

<script data-collect-dnt="true" async="" src="https://scripts.simpleanalyticscdn.com/latest.js"></script></main> <!-- /main -->
<script type="application/vnd.jupyter.widget-state+json">
{"d5677f4560054247957effc97c0381c1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ebddbcacb7d84c3f935f0bde56e24997","IPY_MODEL_71d8a2bb22cd49149c98ca4c6d2886e8","IPY_MODEL_79c5502b53ab460dad47c9006f1bc0b7"],"layout":"IPY_MODEL_1aa4269a7392475cb9546b1db9afb965"}},"ebddbcacb7d84c3f935f0bde56e24997":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b8984b171b3a4d9eb6488032317ce259","placeholder":"​","style":"IPY_MODEL_4553dc8db2b34ccd8e73991afdbea17d","value":"Loading checkpoint shards: 100%"}},"71d8a2bb22cd49149c98ca4c6d2886e8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c33bd63aaed84df99c64739a78a8a712","max":10,"min":0,"orientation":"horizontal","style":"IPY_MODEL_536cf52b6f744767bd83a93580b71288","value":10}},"79c5502b53ab460dad47c9006f1bc0b7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3367afddaa6e45f0807ff275abb7afc6","placeholder":"​","style":"IPY_MODEL_9573e575864e4c24b3b37be971ac9c8e","value":" 10/10 [01:41&lt;00:00,  9.82s/it]"}},"1aa4269a7392475cb9546b1db9afb965":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b8984b171b3a4d9eb6488032317ce259":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4553dc8db2b34ccd8e73991afdbea17d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c33bd63aaed84df99c64739a78a8a712":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"536cf52b6f744767bd83a93580b71288":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3367afddaa6e45f0807ff275abb7afc6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9573e575864e4c24b3b37be971ac9c8e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"226e0b89bf374075a82742545abd6179":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fcd891dc283d42f0a0df5c32920f47aa","IPY_MODEL_b120b43bc3cb485ead2d3d9eff7182b3","IPY_MODEL_192e4a955f404dbc97b26d3111b56807"],"layout":"IPY_MODEL_8a55026abda54a2280eba6b00ca157e2"}},"fcd891dc283d42f0a0df5c32920f47aa":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f7fad5830f6c4335af43a59e1fffee32","placeholder":"​","style":"IPY_MODEL_625844de5cf0476598ea3ac863b86990","value":"Warmup [1]:   0%"}},"b120b43bc3cb485ead2d3d9eff7182b3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_81a45085d4194190bc481986022e787a","max":1500,"min":0,"orientation":"horizontal","style":"IPY_MODEL_605552bf9c354f19ae2f740afba774f0","value":0}},"192e4a955f404dbc97b26d3111b56807":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b06bc9bc31174c1f9cb36daf578e875c","placeholder":"​","style":"IPY_MODEL_c64be3069b514b1dbc4011ac52c85f09","value":" 0/1500 [00:00, ?it/s]"}},"8a55026abda54a2280eba6b00ca157e2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f7fad5830f6c4335af43a59e1fffee32":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"625844de5cf0476598ea3ac863b86990":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"81a45085d4194190bc481986022e787a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"605552bf9c354f19ae2f740afba774f0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b06bc9bc31174c1f9cb36daf578e875c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c64be3069b514b1dbc4011ac52c85f09":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f7d4d1a44b8945c6858855e5bac80f68":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_eddc14c45c44419ebbc9a27f7030c5c8","IPY_MODEL_813b105293bf48b0a8f34284ae82f01a","IPY_MODEL_497af76d7b664c08a0ba92b9fc66a3b0"],"layout":"IPY_MODEL_0e02de5057ea4275b350c33860310e16"}},"eddc14c45c44419ebbc9a27f7030c5c8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_234d8d4896d64d7fb82a2cd7bcb7604b","placeholder":"​","style":"IPY_MODEL_b00ac42329a741928c922edba0316ccd","value":"Warmup [2]:   0%"}},"813b105293bf48b0a8f34284ae82f01a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_9ef1ce6653664072bbd732fa85357b41","max":1500,"min":0,"orientation":"horizontal","style":"IPY_MODEL_85bbd6683b81407abbfeb6f3895a4892","value":0}},"497af76d7b664c08a0ba92b9fc66a3b0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cc0af601364d42b3bfa4bf6d2764e3ce","placeholder":"​","style":"IPY_MODEL_15cba173b20645869ed2d2226c1942bf","value":" 0/1500 [00:00, ?it/s]"}},"0e02de5057ea4275b350c33860310e16":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"234d8d4896d64d7fb82a2cd7bcb7604b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b00ac42329a741928c922edba0316ccd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9ef1ce6653664072bbd732fa85357b41":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"85bbd6683b81407abbfeb6f3895a4892":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cc0af601364d42b3bfa4bf6d2764e3ce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"15cba173b20645869ed2d2226c1942bf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}
</script>
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/www\.utkuturk\.com");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<input type="hidden" id="giscus-base-theme" value="noborder_light">
<input type="hidden" id="giscus-alt-theme" value="noborder_light">
<script>
  function loadGiscus() {
    // Function to get the theme based on body class
    const getTheme = () => {
      let baseTheme = document.getElementById('giscus-base-theme').value;
      let altTheme = document.getElementById('giscus-alt-theme').value;
      return document.body.classList.contains('quarto-dark') ? altTheme : baseTheme;
    };
    const script = document.createElement("script");
    script.src = "https://giscus.app/client.js";
    script.async = true;
    script.dataset.repo = "utkuturk/utkuturk.github.io";
    script.dataset.repoId = "R_kgDOQCZuMw";
    script.dataset.category = "General";
    script.dataset.categoryId = "DIC_kwDOQCZuM84CxOt1";
    script.dataset.mapping = "title";
    script.dataset.reactionsEnabled = "1";
    script.dataset.emitMetadata = "0";
    script.dataset.inputPosition = "top";
    script.dataset.theme = getTheme();
    script.dataset.lang = "en";
    script.crossOrigin = "anonymous";
    // Append the script to the desired div instead of at the end of the body
    document.getElementById("quarto-content").appendChild(script);
  }
  loadGiscus();
</script>
</div> <!-- /content -->




</body></html>